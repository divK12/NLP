{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozJTPzT34PS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53aba9c7-3fb2-4de0-f193-0e2c88e638f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "Vy9gjl2S6RqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaceefb2-5909-4f8d-fc55-6efaeb3c2e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieveing the abstract"
      ],
      "metadata": {
        "id": "1ebxfpAte9vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Unzip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/pdf_json.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/extract')\n",
        "\n"
      ],
      "metadata": {
        "id": "Hv9uWj3Wd8Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "'''extracting abstract from the json'''\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Function to convert JSON to text\n",
        "def json2text(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        paper_content = json.load(file)\n",
        "\n",
        "    abstract = \"\"\n",
        "    # Get the abstract\n",
        "    if 'abstract' in paper_content:\n",
        "        for abs in paper_content['abstract']:\n",
        "            abstract += abs['text']\n",
        "\n",
        "    return (f'{abstract}').lower()\n",
        "\n",
        "# Function to write converted text to file\n",
        "def write_file(filename):\n",
        "    # Convert JSON to text\n",
        "    content = json2text(filename)\n",
        "\n",
        "    # Define the output file path\n",
        "    base_name = os.path.splitext(os.path.basename(filename))[0]\n",
        "    output_dir = '/content/pdf_text'  # desired output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
        "    output_file = os.path.join(output_dir, f'{base_name}.txt')\n",
        "\n",
        "    # Writing the content to a .txt file\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "# Function for parallel processing\n",
        "def par_write(files):\n",
        "    \"\"\"\n",
        "    Read a chunk of files and let the cores of your machine\n",
        "    do the job of format conversion in parallel\n",
        "    \"\"\"\n",
        "    cpu_count = os.cpu_count()\n",
        "    p = Pool(processes=cpu_count)\n",
        "    p.map(write_file, files, chunksize=16)\n",
        "    p.close()\n",
        "\n",
        "# Directory path for JSON files\n",
        "dir_path = '/content/extract/pdf_json'\n",
        "\n",
        "# List all JSON files in the directory\n",
        "json_files = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith('.json')]\n",
        "\n",
        "# Process the files in parallel\n",
        "par_write(json_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydzEP0Z0gBh5",
        "outputId": "031ff5f8-0b5d-4a5d-e147-536cb8a1ecbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.7 s, sys: 371 ms, total: 4.07 s\n",
            "Wall time: 1min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the folder and its contents using shell command\n",
        "!rm -rf /content/extract"
      ],
      "metadata": {
        "id": "zJRxMddLfJl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_urls(text):\n",
        "  '''removes all urls and email ids using regular expression'''\n",
        "\n",
        "  url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "  email_id_pattern=r\"\\S*@\\S*\\s?\"\n",
        "  clean_text=re.sub(url_pattern, '', text)\n",
        "  clean_text=re.sub(email_id_pattern, '', clean_text)\n",
        "\n",
        "  return clean_text\n",
        "\n",
        "def remove_single_letters(text):\n",
        "  '''removes all single letters except a '''\n",
        "  single_letters= r'\\b[b-zB-Z]\\b'\n",
        "  cleaned_text = re.sub(single_letters, '', text)\n",
        "  return cleaned_text\n",
        "\n",
        "def remove_brackets(text):\n",
        "    '''Removes text inside brackets '''\n",
        "    return re.sub(r'\\(.*?\\)', '', text)\n",
        "\n",
        "def remove_num_spl_char(text):\n",
        "  '''removes all numeric and special characters'''\n",
        "  corpus_num=re.sub(r'\\d+', '', text)\n",
        "  return re.sub('[^\\w\\s]', '', corpus_num)\n",
        "\n",
        "def remove_whitespace(text):\n",
        "  '''it removes all extra whitespace'''\n",
        "  return \" \".join(text.split())\n"
      ],
      "metadata": {
        "id": "qkfqLvnFflYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import os\n",
        "import re\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def preprocess(text):\n",
        "\n",
        "    rem_urls=remove_urls(text)\n",
        "    rem_bracket_ct=remove_brackets(rem_urls)\n",
        "    rem_num_spl_char=remove_num_spl_char(rem_bracket_ct)\n",
        "    rem_singlechar=remove_single_letters(rem_num_spl_char)\n",
        "    cleaned_text=remove_whitespace(rem_singlechar)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def preprocess_file(filename):\n",
        "    \"\"\"\n",
        "    Read the content of a file, preprocess it, and save the cleaned text back to the file.\n",
        "    \"\"\"\n",
        "    with open(filename, 'r') as file:\n",
        "        text = file.read()\n",
        "          # Preprocess text\n",
        "    content = preprocess(text)\n",
        "\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "def par_write(files):\n",
        "    \"\"\"\n",
        "    Process a list of files in parallel and save the cleaned text back to the files.\n",
        "    \"\"\"\n",
        "    cpu_count = os.cpu_count()\n",
        "    p = Pool(processes=cpu_count)\n",
        "    p.map(preprocess_file, files, chunksize=50)\n",
        "    p.close()\n",
        "\n",
        "# Example usage\n",
        "dir_path = '/content/pdf_text'\n",
        "txt_files = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith('.txt')]\n",
        "par_write(txt_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KAsjdsogGFd",
        "outputId": "875714a9-3e94-4744-9712-464ec61e1a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.65 s, sys: 149 ms, total: 1.8 s\n",
            "Wall time: 15.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "file_contents = []\n",
        "\n",
        "for file_path in tqdm(txt_files, desc=\"Reading files\"):\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            content = f.read().strip()  # Remove leading/trailing whitespace\n",
        "            if content:  # Only add non-empty content\n",
        "                file_contents.append(content)\n",
        "                if len(file_contents) == 38000:  # Stop after 500 non-empty files\n",
        "                    break\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading {file_path}: {e}\")\n",
        "\n",
        "# Now `file_contents` contains the content of up to 500 non-empty files\n",
        "print(f\"Total non-empty files read: {len(file_contents)}\")\n",
        "\n",
        "# Optionally, write the content to a file\n",
        "dir = \"/content/Abstract_corpus.txt\"\n",
        "with open(dir, 'w') as output_file:\n",
        "    for content in file_contents:\n",
        "        output_file.write(content + \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c5023e-486b-4019-f323-4971872c67ca",
        "id": "vSi36cBYDyby"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading files:  99%|█████████▉| 56043/56528 [00:01<00:00, 42157.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total non-empty files read: 38000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Dataset for training"
      ],
      "metadata": {
        "id": "Synx11y65jcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dir,'r') as f:\n",
        "    corpus=f.read().split(\"\\n\")"
      ],
      "metadata": {
        "id": "P1QhlqVT0p8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFFp9i7SqzlV",
        "outputId": "079f6c69-fd6a-47f2-9164-21be2d324c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T11:57:31.383678Z",
          "iopub.execute_input": "2024-12-05T11:57:31.384038Z",
          "iopub.status.idle": "2024-12-05T11:57:31.389834Z",
          "shell.execute_reply.started": "2024-12-05T11:57:31.384008Z",
          "shell.execute_reply": "2024-12-05T11:57:31.388948Z"
        },
        "id": "yx9LRTBK0auX",
        "outputId": "221c8b53-9e2e-466f-980f-8fbf278b032e"
      },
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'we study the problem usually referred to as group testing in the context of covid given samples collected from patients how should we select and test mixtures of samples to maximize information and minimize the number of tests group testing is a wellstudied problem with several appealing solutions but recent biological studies impose practical constraints for covid that are incompatible with traditional methods furthermore existing methods use unnecessarily restrictive solutions which were devised for settings with more memory and compute constraints than the problem at hand this results in poor utility in the new setting we obtain strong solutions for small values of using evolutionary strategies we then develop a new method combining bloom filters with belief propagation to scale to larger values of with good empirical results we also present a more accurate decoding algorithm that is tailored for specific covid settings this work demonstrates the practical gap between dedicated algorithms and wellknown generic solutions our efforts results in a new and practical multiplex method yielding strong empirical performance without mixing more than a chosen number of patients into the same probe finally we briefly discuss adaptive methods casting them into the framework of adaptive submodularitypreprint under review'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "gZWzdVOtq-FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = [word_tokenize(abstract.lower()) for abstract in corpus]  # Tokenize each abstract and convert to lowercase\n",
        "corpus_txt = [token for sublist in tokens for token in sublist]  # Flatten the list\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T11:57:32.813613Z",
          "iopub.execute_input": "2024-12-05T11:57:32.814475Z",
          "iopub.status.idle": "2024-12-05T11:58:06.155452Z",
          "shell.execute_reply.started": "2024-12-05T11:57:32.81444Z",
          "shell.execute_reply": "2024-12-05T11:58:06.154403Z"
        },
        "id": "p4q2XbzX0auX",
        "outputId": "7a3dd4bc-b8a2-45ff-968f-44d90f87aad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_idx = {}\n",
        "idx_to_word = {}\n",
        "for i, word in enumerate(corpus_txt):\n",
        "    if word not in word_to_idx:\n",
        "        word_to_idx[word] = i\n",
        "        idx_to_word[i] = word\n",
        "\n",
        "vocab_size = len(word_to_idx)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T11:58:06.724374Z",
          "iopub.execute_input": "2024-12-05T11:58:06.724741Z",
          "iopub.status.idle": "2024-12-05T11:58:08.185336Z",
          "shell.execute_reply.started": "2024-12-05T11:58:06.724697Z",
          "shell.execute_reply": "2024-12-05T11:58:08.184501Z"
        },
        "id": "MxNpQ1u90auY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = []\n",
        "target_list = []\n",
        "\n",
        "for i in range(vocab_size - 10):\n",
        "    input_list.append([word_to_idx[word] for word in corpus_txt[i:i + 10]])\n",
        "    target_list.append(word_to_idx[corpus_txt[i + 10]])\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T11:58:08.187223Z",
          "iopub.execute_input": "2024-12-05T11:58:08.187552Z",
          "iopub.status.idle": "2024-12-05T11:58:09.496739Z",
          "shell.execute_reply.started": "2024-12-05T11:58:08.187522Z",
          "shell.execute_reply": "2024-12-05T11:58:09.496027Z"
        },
        "id": "uEQjVcrv0auY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in input_list[19]:\n",
        "    print(idx_to_word[idx])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T11:58:09.497787Z",
          "iopub.execute_input": "2024-12-05T11:58:09.498078Z",
          "iopub.status.idle": "2024-12-05T11:58:09.502441Z",
          "shell.execute_reply.started": "2024-12-05T11:58:09.498051Z",
          "shell.execute_reply": "2024-12-05T11:58:09.501584Z"
        },
        "id": "2MtA8DSw0auY",
        "outputId": "85967df4-a129-4c85-f8c7-6ce1d79553c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "patients\nhow\nshould\nwe\nselect\nand\ntest\nmixtures\nof\nsamples\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = torch.tensor(input_list).to(device)\n",
        "target_list = torch.tensor(target_list).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T11:58:09.50365Z",
          "iopub.execute_input": "2024-12-05T11:58:09.504013Z",
          "iopub.status.idle": "2024-12-05T11:58:10.286071Z",
          "shell.execute_reply.started": "2024-12-05T11:58:09.503973Z",
          "shell.execute_reply": "2024-12-05T11:58:10.285372Z"
        },
        "id": "9AZUCSbh0auY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 6 - Architecture and describe the architecture"
      ],
      "metadata": {
        "id": "rnjEy-JNEiVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, 128)\n",
        "\n",
        "        self.lstm = nn.LSTM(128, hidden_size, 2, bidirectional=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "\n",
        "        x = self.embedding(input_seq)  # (batch_size, seq_len, embed_dim=128)\n",
        "\n",
        "\n",
        "        lstm_out, new_hidden_state = self.lstm(x.permute(1, 0, 2))  # (seq_len, batch_size, hidden_size * 2)\n",
        "\n",
        "\n",
        "        forward_hidden = new_hidden_state[-2][0]  # Forward hidden state from the last layer\n",
        "        backward_hidden = new_hidden_state[-1][0]  # Backward hidden state from the last layer\n",
        "\n",
        "\n",
        "        combined_hidden = (forward_hidden + backward_hidden) / 2  # (batch_size, hidden_size)\n",
        "\n",
        "\n",
        "        output = self.fc(combined_hidden)  # (batch_size, output_size)\n",
        "\n",
        "        return output,new_hidden_state\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T11:58:10.28719Z",
          "iopub.execute_input": "2024-12-05T11:58:10.287496Z",
          "iopub.status.idle": "2024-12-05T11:58:10.293965Z",
          "shell.execute_reply.started": "2024-12-05T11:58:10.287467Z",
          "shell.execute_reply": "2024-12-05T11:58:10.293063Z"
        },
        "id": "801UHhSP0auZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture:\n",
        "\n",
        "\n",
        "*   The first layer is an embedding layer that maps the input sequence of discrete tokens (e.g., word indices) into dense vector representations of size 128.\n",
        "  *  Input shape: (batch_size, seq_len)\n",
        "  *  Output shape: (batch_size, seq_len, embed_dim=128)\n",
        "*    BiLSTM Layer (nn.LSTM): a bidirectional LSTM layer. It takes as input the embedded sequences and learns both forward and backward temporal dependencies in the data.\n",
        "  * The LSTM is configured with:\n",
        "    * An input size of 128 (matching the embedding size).\n",
        "    * A hidden state size of hidden_size.\n",
        "    * 2 layers (stacked LSTMs).\n",
        "  * Output shape:\n",
        "   * LSTM output: (seq_len, batch_size, hidden_size * 2) (concatenation of forward and backward states at each time step).\n",
        "* A linear layer maps the combined hidden representation to the desired output size (output_size).\n",
        "Input shape: (batch_size, hidden_size)\n",
        "Output shape: (batch_size, output_size)\n",
        "* Returns:\n",
        "  * output: The final prediction logits of shape (batch_size, output_size).\n",
        "  * new_hidden_state: The updated hidden state of the LSTM, useful for further computation or recurrent tasks."
      ],
      "metadata": {
        "id": "MnWS_o0u65ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 7: Training and plotting"
      ],
      "metadata": {
        "id": "Cg2sNUui5vu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,input_l,target_l):\n",
        "\n",
        "  batch_size=120\n",
        "  n_batches=len(input_l)//batch_size\n",
        "  if len(input_l)%batch_size!=0:\n",
        "      n_batches+=1\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "  total_loss=0.0\n",
        "  for i in range(n_batches):\n",
        "      input=input_l[i*batch_size:(i+1)*batch_size]\n",
        "      label=target_l[i*batch_size:(i+1)*batch_size]\n",
        "      output,_=model(input)\n",
        "      loss=criterion(output, label)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss+=loss.item()\n",
        "\n",
        "  return total_loss/n_batches\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T11:58:11.833106Z",
          "iopub.execute_input": "2024-12-05T11:58:11.833999Z",
          "iopub.status.idle": "2024-12-05T11:58:11.841207Z",
          "shell.execute_reply.started": "2024-12-05T11:58:11.833965Z",
          "shell.execute_reply": "2024-12-05T11:58:11.840244Z"
        },
        "id": "wyta49nd0auZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=20\n",
        "loss=[]\n",
        "input_size=vocab_size\n",
        "output_size=vocab_size\n",
        "hidden_size=128\n",
        "\n",
        "model=BiLSTM(input_size, output_size, hidden_size).to(device)\n",
        "for i in range(epochs):\n",
        "  loss.append(train(model,input_list,target_list))\n",
        "  print(f\"Epoch {i+1}/{epochs}, Loss: {loss[-1]}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T11:59:16.588292Z",
          "iopub.execute_input": "2024-12-05T11:59:16.588645Z",
          "iopub.status.idle": "2024-12-05T12:12:43.446525Z",
          "shell.execute_reply.started": "2024-12-05T11:59:16.588616Z",
          "shell.execute_reply": "2024-12-05T12:12:43.445378Z"
        },
        "id": "wPib6T640auZ",
        "outputId": "366922a4-dedf-42f8-fff2-8a0934705702"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/20, Loss: 7.534766444465182\nEpoch 2/20, Loss: 6.911831600934464\nEpoch 3/20, Loss: 6.79532502502795\nEpoch 4/20, Loss: 6.663064009306447\nEpoch 5/20, Loss: 6.525866389116704\nEpoch 6/20, Loss: 6.3817294613415045\nEpoch 7/20, Loss: 6.268062424343943\nEpoch 8/20, Loss: 6.186849839797873\nEpoch 9/20, Loss: 6.073003002823583\nEpoch 10/20, Loss: 5.987416133501672\nEpoch 11/20, Loss: 5.919863439395728\nEpoch 12/20, Loss: 5.856034007609285\nEpoch 13/20, Loss: 5.8086378422793965\nEpoch 14/20, Loss: 5.762180236633251\nEpoch 15/20, Loss: 5.736493552757414\nEpoch 16/20, Loss: 5.700396503675853\nEpoch 17/20, Loss: 5.684711731506499\nEpoch 18/20, Loss: 5.663299322759868\nEpoch 19/20, Loss: 5.6406913861533665\nEpoch 20/20, Loss: 5.628498155391769\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T12:14:32.477042Z",
          "iopub.execute_input": "2024-12-05T12:14:32.477408Z",
          "iopub.status.idle": "2024-12-05T12:14:32.727483Z",
          "shell.execute_reply.started": "2024-12-05T12:14:32.47738Z",
          "shell.execute_reply": "2024-12-05T12:14:32.726544Z"
        },
        "id": "ppi4Kp3e0auZ",
        "outputId": "b1ac0185-6f71-4196-fca9-9f3f8a3ce613"
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[<matplotlib.lines.Line2D at 0x79b931d85ff0>]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIfUlEQVR4nO3deXwTdf4/8FeSNkmvpPcRGko5ylFKW65SCotHFVhWQF2uBcuNi1UEdBX8reL1FXXFVVcBQS5FQF3ORQGhWgRa7hsE2lIovWmhSQ+aHpnfH9BopC1NaTtJ+no+HvOQzHxm+v44xL6c+cxnJIIgCCAiIiKyYlKxCyAiIiK6FwYWIiIisnoMLERERGT1GFiIiIjI6jGwEBERkdVjYCEiIiKrx8BCREREVo+BhYiIiKyeg9gFNAWj0Yjs7Gy4ublBIpGIXQ4RERE1gCAIKC4uhkajgVRa/zUUuwgs2dnZ0Gq1YpdBREREjXDt2jUEBgbW28YuAoubmxuA2x1WqVQiV0NEREQNodfrodVqTb/H62MXgaXmNpBKpWJgISIisjENGc7BQbdERERk9RhYiIiIyOoxsBAREZHVY2AhIiIiq8fAQkRERFaPgYWIiIisHgMLERERWT0GFiIiIrJ6DCxERERk9RhYiIiIyOoxsBAREZHVY2AhIiIiq8fAUg9dWSU+/SkFL/33lNilEBERtWoMLPWQSoFFuy/h26OZuF5sELscIiKiVouBpR5uSkd08nUFAJy8ViRuMURERK2YRYGlXbt2kEgkdy3x8fG1tl+9evVdbZVKpVkbQRDw2muvISAgAE5OToiNjUVKSkrje9TEIrTuAICT126KWwgREVErZlFgOXLkCHJyckzL7t27AQCjRo2qcx+VSmW2z9WrV822v//++/jkk0+wdOlSHDp0CC4uLhg8eDDKy8sb0Z2mF9nWAwBwIqNI3EKIiIhaMQdLGvv4+Jh9fvfdd9GhQwcMGjSozn0kEgn8/f1r3SYIAj766CP885//xIgRIwAAX375Jfz8/LBlyxaMHTvWkvKaRc0VltOZOlQbBcikEnELIiIiaoUaPYaloqICa9euxZQpUyCR1P1LvKSkBEFBQdBqtRgxYgTOnTtn2paeno7c3FzExsaa1qnVakRFRSE5ObmxpTWpED83OMtlKDFUIe16idjlEBERtUqNDixbtmxBUVERJk2aVGebzp07Y+XKldi6dSvWrl0Lo9GI/v37IzMzEwCQm5sLAPDz8zPbz8/Pz7StNgaDAXq93mxpLjKpBD0C1QCAExkcx0JERCSGRgeWFStWYOjQodBoNHW2iY6ORlxcHCIiIjBo0CBs2rQJPj4++Pzzzxv7YwEACxcuhFqtNi1arfa+jncvEdrb41j4pBAREZE4GhVYrl69ij179mDatGkW7efo6IjIyEikpqYCgGlsS15enlm7vLy8Ose9AMD8+fOh0+lMy7Vr1yzsgWVqxrFw4C0REZE4GhVYVq1aBV9fXwwbNsyi/aqrq3HmzBkEBAQAAIKDg+Hv74+EhARTG71ej0OHDiE6OrrO4ygUCqhUKrOlOUW2dQcAXMorRqmhqll/FhEREd3N4sBiNBqxatUqTJw4EQ4O5g8ZxcXFYf78+abPb775Jn788UdcvnwZx48fx4QJE3D16lXTlRmJRILZs2fj7bffxrZt23DmzBnExcVBo9Fg5MiR99ezJuSnUkKjVsIo3H5aiIiIiFqWRY81A8CePXuQkZGBKVOm3LUtIyMDUulvGejmzZuYPn06cnNz4eHhgV69eiEpKQndunUztXnppZdQWlqKGTNmoKioCAMGDMDOnTvvmmBObBFt3ZF9JhcnrxUhuoOX2OUQERG1KhJBEASxi7hfer0earUaOp2u2W4PLfslDe/8cAGPdvPDsrjezfIziIiIWhNLfn/zXUINVDPj7clrRbCDjEdERGRTGFgaqLtGDZlUgvxiA3J01vHaACIiotaCgaWBnOQydPF3A8DHm4mIiFoaA4sFah5v5pubiYiIWhYDiwU44y0REZE4GFgs8Ps3N1dWG8UthoiIqBVhYLFAe28XqJQOMFQZcTG3WOxyiIiIWg0GFgtIpRKE17xXiLeFiIiIWgwDi4UiTS9C5MBbIiKilsLAYqHfTyBHRERELYOBxUI1t4QuXy+FrqxS3GKIiIhaCQYWC3m6yBHk5QwAOJlZJG4xRERErQQDSyPUjGM5yRlviYiIWgQDSyPUzMfCGW+JiIhaBgNLI0Twzc1EREQtioGlEboFqCB3kOJmWSWuFpaJXQ4REZHdY2BpBLmDFKEaFQA+3kxERNQSGFgaKYITyBEREbUYBpZG4gRyRERELYeBpZFqHm0+n6NHeWW1uMUQERHZOQaWRgr0cIKXixyV1QLOZevFLoeIiMiuMbA0kkQiQWRbdwC8LURERNTcGFjuw28TyBWJWgcREZG9Y2C5DxHa2wNv+aQQERFR82JguQ89tGpIJEDmzVsoKDGIXQ4REZHdYmC5DyqlIzr6uALgixCJiIiaEwPLfTJNIMcXIRIRETUbBpb7xAnkiIiImh8Dy32qucJy6poO1Ua+uZmIiKg5MLDcpxA/Vzg5ylBiqELa9RKxyyEiIrJLDCz3yUEmRY9ANQAOvCUiImouDCxNIOLOjLcnOI6FiIioWTCwNIGaFyFyAjkiIqLmYVFgadeuHSQSyV1LfHx8re2XL1+OgQMHwsPDAx4eHoiNjcXhw4fN2kyaNOmu4w0ZMqTxPRJBzZNCl/KKUWqoErkaIiIi+2NRYDly5AhycnJMy+7duwEAo0aNqrV9YmIixo0bh59//hnJycnQarV49NFHkZWVZdZuyJAhZsddv359I7sjDj+VEgFqJYwCcCZLJ3Y5REREdsfBksY+Pj5mn99991106NABgwYNqrX9119/bfb5iy++wMaNG5GQkIC4uDjTeoVCAX9/f0tKsToRWnfk6HJxIqMI/dp7iV0OERGRXWn0GJaKigqsXbsWU6ZMgUQiadA+ZWVlqKyshKenp9n6xMRE+Pr6onPnzpg5cyYKCwsbW5ZoIu8MvD3JGW+JiIianEVXWH5vy5YtKCoqwqRJkxq8z8svvwyNRoPY2FjTuiFDhuCJJ55AcHAw0tLS8Morr2Do0KFITk6GTCar9TgGgwEGw28vG9Tr9Y3tRpP57c3NRRAEocEhjoiIiO6t0YFlxYoVGDp0KDQaTYPav/vuu9iwYQMSExOhVCpN68eOHWv6c1hYGHr06IEOHTogMTERDz/8cK3HWrhwId54443Glt4swtqoIZNKkF9sQI6uHBp3J7FLIiIishuNuiV09epV7NmzB9OmTWtQ+w8++ADvvvsufvzxR/To0aPetu3bt4e3tzdSU1PrbDN//nzodDrTcu3aNYvqbw5Ochk6+7kB4HuFiIiImlqjAsuqVavg6+uLYcOG3bPt+++/j7feegs7d+5E796979k+MzMThYWFCAgIqLONQqGASqUyW6zBb+NYikStg4iIyN5YHFiMRiNWrVqFiRMnwsHB/I5SXFwc5s+fb/r83nvv4dVXX8XKlSvRrl075ObmIjc3FyUlt9+5U1JSgn/84x84ePAgrly5goSEBIwYMQIdO3bE4MGD77NrLS+CE8gRERE1C4sDy549e5CRkYEpU6bctS0jIwM5OTmmz0uWLEFFRQX++te/IiAgwLR88MEHAACZTIbTp09j+PDhCAkJwdSpU9GrVy/s27cPCoXiProljporLGeydKisNopbDBERkR2RCIIgiF3E/dLr9VCr1dDpdKLeHjIaBYS/+SOKy6uw/bkB6N5GLVotRERE1s6S3998l1ATkkolv90W4jgWIiKiJsPA0sRqAsvJjCJR6yAiIrInDCxNjDPeEhERNT0GliYWHugOAEi7XgpdWaW4xRAREdkJBpYm5uWqQFtPZwDAqcwicYshIiKyEwwszYATyBERETUtBpZmwAnkiIiImhYDSzMwPSl07fabm4mIiOj+MLA0g24aFeQyKW6WVSLjRpnY5RAREdk8BpZmoHCQoZvm9ox9JzgfCxER0X1jYGkmv78tRERERPeHgaWZ1DwpxCn6iYiI7h8DSzOJ1HoAAM5n61BeWS1yNURERLaNgaWZaD2d4OkiR2W1gPM5erHLISIismkMLM1EIpEgki9CJCIiahIMLM3INIEcx7EQERHdFwaWZhTBNzcTERE1CQaWZhSudYdEAly7cQsFJQaxyyEiIrJZDCzNSKV0RAcfVwAcx0JERHQ/GFiaGSeQIyIiun8MLM0s0jSOpUjUOoiIiGwZA0szq7nCcupaEYxGvrmZiIioMRhYmllnPzc4OcpQbKhC2vUSscshIiKySQwszcxBJkVYoBoA52MhIiJqLAaWFlAz4+0JPilERETUKAwsLYBPChEREd0fBpYWENn29pubL+bqUVZRJXI1REREtoeBpQX4q5XwVylhFIDTmTqxyyEiIrI5DCwthLeFiIiIGo+BpYWYJpDjwFsiIiKLMbC0kJorLCf45mYiIiKLMbC0kLBANWRSCfL0BuToboldDhERkU1hYGkhznIHdPZzA8DbQkRERJZiYGlBEXfGsXDGWyIiIstYFFjatWsHiURy1xIfH1/nPt999x26dOkCpVKJsLAw/PDDD2bbBUHAa6+9hoCAADg5OSE2NhYpKSmN642VMz0pxCssREREFrEosBw5cgQ5OTmmZffu3QCAUaNG1do+KSkJ48aNw9SpU3HixAmMHDkSI0eOxNmzZ01t3n//fXzyySdYunQpDh06BBcXFwwePBjl5eX30S3r1PPOFZbTWUWoqjaKWwwREZENkQiCIDR259mzZ2P79u1ISUmBRCK5a/uYMWNQWlqK7du3m9b169cPERERWLp0KQRBgEajwQsvvIAXX3wRAKDT6eDn54fVq1dj7NixDapDr9dDrVZDp9NBpVI1tjvNzmgUEP7mjygur8L25wagexu12CURERGJxpLf340ew1JRUYG1a9diypQptYYVAEhOTkZsbKzZusGDByM5ORkAkJ6ejtzcXLM2arUaUVFRpja1MRgM0Ov1ZostkEolCA90B8AJ5IiIiCzR6MCyZcsWFBUVYdKkSXW2yc3NhZ+fn9k6Pz8/5ObmmrbXrKurTW0WLlwItVptWrRabSN70fI44y0REZHlGh1YVqxYgaFDh0Kj0TRlPQ0yf/586HQ603Lt2rUWr6Gxama8PZHBCeSIiIgayqExO129ehV79uzBpk2b6m3n7++PvLw8s3V5eXnw9/c3ba9ZFxAQYNYmIiKizuMqFAooFIrGlC66missaddLobtVCbWTo7gFERER2YBGXWFZtWoVfH19MWzYsHrbRUdHIyEhwWzd7t27ER0dDQAIDg6Gv7+/WRu9Xo9Dhw6Z2tgbL1cFtJ5OAIDTmUXiFkNERGQjLA4sRqMRq1atwsSJE+HgYH6BJi4uDvPnzzd9fv7557Fz504sWrQIFy5cwOuvv46jR4/i2WefBQBIJBLMnj0bb7/9NrZt24YzZ84gLi4OGo0GI0eOvL+eWbFIrQcA4ATnYyEiImoQi28J7dmzBxkZGZgyZcpd2zIyMiCV/paB+vfvj3Xr1uGf//wnXnnlFXTq1AlbtmxB9+7dTW1eeukllJaWYsaMGSgqKsKAAQOwc+dOKJXKRnbJ+kVo3bHtVDYH3hIRETXQfc3DYi1sZR6WGsczbuKJxUnwdJHj2D9j63wsnIiIyJ61yDws1HihGhXkMilulFYg40aZ2OUQERFZPQYWESgcZOiquZ0keVuIiIjo3hhYRBJ55/FmDrwlIiK6NwYWkZgmkOMVFiIiontiYBFJzQRyv2brYaiqFrcYIiIiK8fAIpK2ns7wdJGjotqI89m28fJGIiIisTCwiEQikZiusnAcCxERUf0YWERUE1iSLxfCDqbDISIiajYMLCKK6egNANh9Pg//3HIWVdVGkSsiIiKyTgwsIuoV5IFX/9INEgnw9aEMTPvyKEoMVWKXRUREZHUYWEQ2dUAwlozvBaWjFIkXr2P00mTk6srFLouIiMiqMLBYgSHd/bFhRjS8XeU4n6PHyM8O8MkhIiKi32FgsRIRWndsfiYGHXxckKsvx6ilSUi8mC92WURERFaBgcWKaD2dsWlmDPq190RpRTWmrjmKdYcyxC6LiIhIdAwsVkbt7Igvp0Thicg2qDYKeGXzGby74wKMRj72TERErRcDixWSO0ixaHQ4Zsd2AgAs3ZuG5zacQHklp/AnIqLWiYHFSkkkEsyODcGiUeFwlEnw/ekcjP/iEG6UVohdGhERUYtjYLFyT/YKxJopfeGmdMCxqzfxxOIDSC8oFbssIiKiFsXAYgP6d/DG5mf6I9DDCVcKy/D44gM4cuWG2GURERG1GAYWG9HR1w2bn4lBeKAaRWWVGL/8ELadyha7LCIiohbBwGJDfNwU2DAjGoND/VBRbcSs9Sfw2c+pfHEiERHZPQYWG+Mkl2Hx+F6YOiAYAPCvXRcxb+MZVPLFiUREZMcYWGyQTCrBq3/phjdHhEIqAb45eg1TVh+BvrxS7NKIiIiaBQOLDYuLboflcb3h5CjDvpQCjF6ajOyiW2KXRURE1OQYWGzcw1398O3T0fBxU+BCbjFGfnYAZ7N0YpdFRETUpBhY7EBYoBpb4mMQ4ueK/GIDRn+ejJ8u5IldFhERUZNhYLETbdyd8N+Z/TGgozfKKqoxbc1RfJV8ReyyiIiImgQDix1RKR2xanIfjOmthVEAXt16Dm9vP88XJxIRkc1jYLEzjjIp3n0yDP8Y3BkA8MX+dMz99iSq+NgzERHZMAYWOySRSBD/YEd8PDYCDlIJtpzMxpxvTzG0EBGRzWJgsWMjItrg07/1hKNMgv+dysasDSc4wRwREdkkBhY7N6S7P5aM7wW5TIofzuTi2XXHUVHF0EJERLaFgaUViO3mh8+f6gW5gxS7zuXhma+PwVBVLXZZREREDWZxYMnKysKECRPg5eUFJycnhIWF4ejRo3W2nzRpEiQSyV1LaGioqc3rr79+1/YuXbo0rkdUqwe7+OKLuN5QOEix59d8/P2rYyivZGghIiLbYFFguXnzJmJiYuDo6IgdO3bg/PnzWLRoETw8POrc5+OPP0ZOTo5puXbtGjw9PTFq1CizdqGhoWbt9u/f37geUZ3+FOKDlZP6QOkoxc8Xr2P6l0cZWoiIyCY4WNL4vffeg1arxapVq0zrgoOD691HrVZDrVabPm/ZsgU3b97E5MmTzQtxcIC/v78l5VAjxHT0xurJfTFl9RHsSynAlNVHsGJiHzjJZWKXRkREVCeLrrBs27YNvXv3xqhRo+Dr64vIyEgsX77coh+4YsUKxMbGIigoyGx9SkoKNBoN2rdvj/HjxyMjI6POYxgMBuj1erOFGq5fey+smdIXLnIZktIKMWnVYZQaqsQui4iIqE4WBZbLly9jyZIl6NSpE3bt2oWZM2di1qxZWLNmTYP2z87Oxo4dOzBt2jSz9VFRUVi9ejV27tyJJUuWID09HQMHDkRxcXGtx1m4cKHpyo1arYZWq7WkGwSgTztPfDk1Cm4KBxxKv4FJqw6jhKGFiIislEQQhAbP2y6Xy9G7d28kJSWZ1s2aNQtHjhxBcnLyPfdfuHAhFi1ahOzsbMjl8jrbFRUVISgoCB9++CGmTp1613aDwQCDwWD6rNfrodVqodPpoFKpGtodAnDyWhGeWnEIxeVV6NnWHaun9IVK6Sh2WURE1Aro9Xqo1eoG/f626ApLQEAAunXrZraua9eu9d6+qSEIAlauXImnnnqq3rACAO7u7ggJCUFqamqt2xUKBVQqldlCjROhdce6af2gdnLE8YwiPLXiMHS3KsUui4iIyIxFgSUmJgYXL140W3fp0qW7xqPUZu/evUhNTa31iskflZSUIC0tDQEBAZaUR40UFqjGuulR8HB2xKlrRZjwxSEUlVWIXRYREZGJRYFlzpw5OHjwIN555x2kpqZi3bp1WLZsGeLj401t5s+fj7i4uLv2XbFiBaKiotC9e/e7tr344ovYu3cvrly5gqSkJDz++OOQyWQYN25cI7pEjRGqUWPd9H7wdJHjTJYOf1t+CDdKGVqIiMg6WBRY+vTpg82bN2P9+vXo3r073nrrLXz00UcYP368qU1OTs5dt4h0Oh02btxY59WVzMxMjBs3Dp07d8bo0aPh5eWFgwcPwsfHpxFdosbqGqDChhn94O2qwPkcPf62/CAKSgz33pGIiKiZWTTo1lpZMmiH7i01vwR/W34Q+cUGdPJ1xbrp/eDjphC7LCIisjPNNuiWWoeOvq7YMKMf/FVKpOSXYOyyZOTry8Uui4iIWjEGFqpVex9XfPN0P2jUSqRdL8WYZQeRo7sldllERNRKMbBQnYK8XPDN09Fo4+6E9IJSjPn8ILKKGFqIiKjlMbBQvbSezvjm6X5o6+mMjBtlGPN5Mq7dKBO7LCIiamUYWOieAj1uh5Z2Xs7IvHkLY5cdREYhQwsREbUcBhZqkAC1E755OhrtvV2QVXQLY5YlI72gVOyyiIiolWBgoQbzUymx4el+6OjrihxdOcZ8noy06yVil0VERK0AAwtZxNdNiQ0z+qGznxvyiw0Y8/lBpOYztBARUfNiYCGLebsqsH5GP3QNUKGgxIC/LT/I20NERNSsGFioUTxd5Ph6WhS6+N++0jJu2UFcLWRoISKi5sHAQo3m6SLH2mlR6OTrilx9Of62/BAfeSYiombBwEL3xdtVga+nR6G9z+2nh8Yt5+RyRETU9BhY6L75uimxfno/BHu7IPPmLYzjNP5ERNTEGFioSfiplFg3Pco0I+7flh9CHl+YSERETYSBhZpMgNoJ66ZHmd499LflB3G92CB2WUREZAcYWKhJBXo4Y8OM397y/LflB1FQwtBCRET3h4GFmpzW0xnrZ/SDv0qJlPwSTPjiEG6UVohdFhER2TAGFmoWQV4uWDc9Cr5uClzILcaELw6hqIyhhYiIGoeBhZpNex9XrJveD96ucpzP0eOpFYehu1UpdllERGSDGFioWXX0vR1aPF3kOJOlQ9zKw9CXM7QQEZFlGFio2YX4ueHraVFwd3bEqWtFmLTyMEoMVWKXRURENoSBhVpE1wAV1k6NgkrpgOMZRZiy6gjKKhhaiIioYRhYqMV0b6PG2mlRcFM64PCVG5iy+ghuVVSLXRYREdkABhZqUT0C3fHllL5wVTjg4OUbmP7lUZRXMrQQEVH9GFioxUW29cCaKX3gIpdhf2oBZnx1jKGFiIjqxcBCougV5IlVk/vCyVGGXy5dxzNfH4ehiqGFiIhqx8BCoukb7IkVk3pD6SjFTxfy8ey6E6isNopdFhERWSEGFhJV/w7e+CKuD+QOUuw+n4dZ6xlaiIjobgwsJLoBnbyx7KlekMuk2HE2F7O/OYkqhhYiIvodBhayCg909sXSp3rCUSbB96dz8MJ3p1BtFMQui4iIrAQDC1mNh7r44bO/9YSDVIKtJ7Px0n9Pw8jQQkREYGAhK/NoqD/+My4SMqkEG49nYv6mMwwtRETEwELWZ2hYAD4aEwGpBPjm6DX83w+/QhAYWoiIWjOLA0tWVhYmTJgALy8vODk5ISwsDEePHq2zfWJiIiQSyV1Lbm6uWbvPPvsM7dq1g1KpRFRUFA4fPmx5b8huPBauwft/DQcArNifjv/8lCpyRUREJCaLAsvNmzcRExMDR0dH7NixA+fPn8eiRYvg4eFxz30vXryInJwc0+Lr62va9s0332Du3LlYsGABjh8/jvDwcAwePBj5+fmW94jsxl97BeK1v3QDAHy4+xJWH0gXuSIiIhKLRLDgWvu8efNw4MAB7Nu3r8E/IDExEQ8++CBu3rwJd3f3WttERUWhT58++PTTTwEARqMRWq0Wzz33HObNm3fPn6HX66FWq6HT6aBSqRpcG9mGf+++hI8TUgAAH44OxxM9A0WuiIiImoIlv78tusKybds29O7dG6NGjYKvry8iIyOxfPnyBu0bERGBgIAAPPLIIzhw4IBpfUVFBY4dO4bY2NjfipJKERsbi+Tk5FqPZTAYoNfrzRayX7NjO2FS/3YAgH/89zR+PJdb/w5ERGR3LAosly9fxpIlS9CpUyfs2rULM2fOxKxZs7BmzZo69wkICMDSpUuxceNGbNy4EVqtFg888ACOHz8OACgoKEB1dTX8/PzM9vPz87trnEuNhQsXQq1WmxatVmtJN8jGSCQSvPaXbniyZyCqjQKeXX8CSWkFYpdFREQtyKJbQnK5HL1790ZSUpJp3axZs3DkyJE6r4bUZtCgQWjbti2++uorZGdno02bNkhKSkJ0dLSpzUsvvYS9e/fi0KFDd+1vMBhgMBhMn/V6PbRaLW8J2bmqaiPi1x3HrnN5cJHL8PX0fojQuotdFhERNVKz3RIKCAhAt27dzNZ17doVGRkZFhXYt29fpKbefurD29sbMpkMeXl5Zm3y8vLg7+9f6/4KhQIqlcpsIfvnIJPi47GRiOnohdKKakxadRiX8orFLouIiFqARYElJiYGFy9eNFt36dIlBAUFWfRDT548iYCAAAC3r9r06tULCQkJpu1GoxEJCQlmV1yIAEDpKMOyp3ojQuuOorJKTPjiEDIKy8Qui4iImplFgWXOnDk4ePAg3nnnHaSmpmLdunVYtmwZ4uPjTW3mz5+PuLg40+ePPvoIW7duRWpqKs6ePYvZs2fjp59+Mttn7ty5WL58OdasWYNff/0VM2fORGlpKSZPntwEXSR746JwwOrJfdDZzw35xQZMWHEI+fpyscsiIqJm5GBJ4z59+mDz5s2YP38+3nzzTQQHB+Ojjz7C+PHjTW1ycnLMbhFVVFTghRdeQFZWFpydndGjRw/s2bMHDz74oKnNmDFjcP36dbz22mvIzc1FREQEdu7ceddAXKIa7s5yfDW1L/66NBkZN8rw1IrD+ObpfnB3lotdGhERNQOLBt1aK87D0npdu1GGJ5ckIb/YgAitO76eFgUXhUU5nIiIRNJsg26JrI3W0xlrp0XB3dkRJ68VYcZXR1FeWS12WURE1MQYWMjmhfi5YfXkvnCRy3AgtRCz1p9AVbVR7LKIiKgJMbCQXYjQumN5XG/IHaT48XweXt54Bkajzd/tJCKiOxhYyG707+iNT8dFQiaVYOPxTLy5/TzsYIgWERGBgYXszKOh/vhgVA8AwOqkK/hoT4rIFRERUVNgYCG783hkIN4YHgoA+DghBSv3p4tcERER3S8GFrJLE/u3w9xHQgAAb24/j++OXhO5IiIiuh8MLGS3nnuoI6YOCAYAvLzxNHaerf3t30REZP0YWMhuSSQS/HNYV4zqFQijAMxafwL7UwrELouIiBqBgYXsmkQiwcInwjAk1B8V1UbM+OoojmfcFLssIiKyEAML2T0HmRQfj4vAwE7eKKuoxuRVR3AhVy92WUREZAEGFmoVFA4yLJ3QC5Ft3aG7VYmnVhzGlYJSscsiIqIGYmChVsNF4YDVk/qii78brhcbMGHFIeTqysUui4iIGoCBhVoVtbMjvpzaF+28nJF58xaeXJKEi7nFYpdFRET3wMBCrY6vmxJfTY1COy9nZBXdDi0/X8wXuywiIqoHAwu1SlpPZ2x+JgZRwZ4oMVRh6uojWH2AM+ISEVkrBhZqtTxc5PhqahRG9749T8vr/zuP17aeRVW1UezSiIjoDxhYqFWTO0jx3pM9MH9oF0gkwJfJVzF59RHoyyvFLo2IiH6HgYVaPYlEgqcHdcDSCb3g5CjDvpQCPLE4CRmFZWKXRkREdzCwEN0xONQf3/09Gv4qJVLzSzBy8QEcuXJD7LKIiAgMLERmurdRY+uzMQhro8aN0gqMX34Im45nil0WEVGrx8BC9Ad+KiW+fTra9P6hud+ewge7LsJoFMQujYio1WJgIaqFk1yGxeN74pkHOgAAPv05Fc+uP45bFdUiV0ZE1DoxsBDVQSqV4KUhXfDBqHA4yiT44UwuxixLRr6e0/kTEbU0Bhaie/hrr0B8Pa0fPJwdcTpThxGfHcC5bJ3YZRERtSoMLEQN0DfYE1viY9DBxwU5unKMWpqM3efzxC6LiKjVYGAhaqAgLxdseiYGAzp6o6yiGjO+Ooplv6RBEDgYl4iouTGwEFlA7eSIVZP7YHxUWwgC8M4PFzB/0xlUVHE6fyKi5sTAQmQhR5kUb4/sjgWPdYNUAmw4cg0TVx5GUVmF2KUREdktBhaiRpBIJJgcE4wvJvaGi1yG5MuFeHxxEi5fLxG7NCIiu8TAQnQfHurih43P9EcbdyekF5Ti8cVJSEorELssIiK7w8BCdJ+6+KuwJT4GEVp36G5VIm7FYXxzJEPssoiI7AoDC1ET8HFTYMOMfngsXIMqo4CXN57BOz/8impO509E1CQsDixZWVmYMGECvLy84OTkhLCwMBw9erTO9ps2bcIjjzwCHx8fqFQqREdHY9euXWZtXn/9dUgkErOlS5culveGSERKRxk+GRuB2bGdAADLfrmM4Z/ux/GMmyJXRkRk+ywKLDdv3kRMTAwcHR2xY8cOnD9/HosWLYKHh0ed+/zyyy945JFH8MMPP+DYsWN48MEH8dhjj+HEiRNm7UJDQ5GTk2Na9u/f37geEYlIIpFgdmwIPhkXCTelA85l6/HE4iTM23gaN0r5FBERUWNJBAtmvZo3bx4OHDiAffv23dcPDQ0NxZgxY/Daa68BuH2FZcuWLTh58mSjjqfX66FWq6HT6aBSqe6rNqKmUlBiwLs7LuC/xzIBAO7OjnhpcBeM6aOFTCoRuToiIvFZ8vvboiss27ZtQ+/evTFq1Cj4+voiMjISy5cvt6g4o9GI4uJieHp6mq1PSUmBRqNB+/btMX78eGRk1D1o0WAwQK/Xmy1E1sbbVYEPRoXju79Ho4u/G4rKKvHK5jN4YvEBnM4sErs8IiKbYlFguXz5MpYsWYJOnTph165dmDlzJmbNmoU1a9Y0+BgffPABSkpKMHr0aNO6qKgorF69Gjt37sSSJUuQnp6OgQMHori4uNZjLFy4EGq12rRotVpLukHUovq088T25wbgtb90g6vCAafuvEDx/20+w8nmiIgayKJbQnK5HL1790ZSUpJp3axZs3DkyBEkJyffc/9169Zh+vTp2Lp1K2JjY+tsV1RUhKCgIHz44YeYOnXqXdsNBgMMBoPps16vh1ar5S0hsnr5+nIs3HEBm09kAQA8XeSYN6QL/torEFLeJiKiVqbZbgkFBASgW7duZuu6du1a7+2bGhs2bMC0adPw7bff1htWAMDd3R0hISFITU2tdbtCoYBKpTJbiGyBr0qJf4+JwIYZ/RDi54obpRV4aeNp/HVpEs5m6cQuj4jIalkUWGJiYnDx4kWzdZcuXUJQUFC9+61fvx6TJ0/G+vXrMWzYsHv+nJKSEqSlpSEgIMCS8ohsRr/2Xvh+1kD8vz93hYtchuMZRRj+6X4s2HoWuluVYpdHRGR1LAosc+bMwcGDB/HOO+8gNTUV69atw7JlyxAfH29qM3/+fMTFxZk+r1u3DnFxcVi0aBGioqKQm5uL3Nxc6HS//d/kiy++iL179+LKlStISkrC448/DplMhnHjxjVBF4msk6NMiul/ao+EFx7AX3oEwCgAa5Kv4uFFidh4LBMW3K0lIrJ7FgWWPn36YPPmzVi/fj26d++Ot956Cx999BHGjx9vapOTk2N2i2jZsmWoqqpCfHw8AgICTMvzzz9vapOZmYlx48ahc+fOGD16NLy8vHDw4EH4+Pg0QReJrJu/WolP/9YTX0+LQgcfFxSUVOCF705h9OfJuJDLJ+CIiAALB91aK87DQvaiosqIFfvT8UlCCm5VVkMmlWBidDvMeaQT3JSOYpdHRNSkmm3QLRE1L7mDFDMf6ICEFwbhz2H+qDYKWHkgHQ8t2outJ7N4m4iIWi1eYSGyYnsvXcfr284hvaAUANCvvSfeGtEdnfzcRK6MiOj+8QoLkZ0YFOKDnbMH4h+DO0PpKMXByzcw9ON9eOeHX1FiqBK7PCKiFsPAQmTlFA4yxD/YEbvnDMKj3fxQZRSw7JfLeOTDvTiTyblbiKh1YGAhshFaT2csi+uNlZN6o62nM3J05Rj1eRJ2ns0RuzQiombHwEJkYx7q4oftswbgTyE+KK804u9rj2NJYhoH5BKRXWNgIbJBKqUjVk7sjbjo27NMv7fzAl7672lUVBlFroyIqHkwsBDZKAeZFG+O6I43hodCKgG+O5aJCSsO4WYp3wBNRPaHgYXIxk3s3w4rJ/WBq8IBh9Nv4PHFB5B2vUTssoiImhQDC5EdeKCzLzbO7I9ADydcKSzD458dQFJqgdhlERE1GQYWIjvR2d8NW+Jj0LOtO/TlVYhbeRgbDmfce0ciIhvAwEJkR7xdFVg3vR+Gh2tQZRQwb9MZ/N/351Ft5BNERGTbGFiI7IzSUYaPx0ZgTmwIAGD5vnQ8/dUxlHJmXCKyYQwsRHZIIpHg+dhO+GRcJOQOUuz5NQ+jliYjR3dL7NKIiBqFgYXIjg0P12DDjH7wdpXjfI4eIz49gNOZRWKXRURkMQYWIjvXs60HNj8Tg85+bsgvNmD058nYcYbT+RORbWFgIWoFtJ7O+O/MaDzQ+fZ0/jO/Po7Pfk7ldP5EZDMYWIhaCTelI76I641J/dsBAP616yJe/O40DFXV4hZGRNQADCxErYiDTIrXh4firRGhkEkl2Hg8E099cRg3OJ0/EVk5BhaiVuip6NvT+bspHHD4yu3p/FPzOZ0/EVkvBhaiVmpQiA82PnN7Ov+rhWV4YvEBHOB0/kRkpRhYiFqxED83bI2PQa8gD9N0/usOcTp/IrI+DCxErZyXqwJfT4vCyAgNqo0CXtl8Bm9v53T+RGRdGFiICEpHGf49JgJzH7k9nf8X+9MxadVhZN4sE7kyIqLbGFiICMDt6fxnPdwJ/xkXCYWDFPtSCvDov3/Biv3pvNpCRKJjYCEiM4+Fa/D9rIHo284TZRXVeGv7eTyx+ADOZ+vFLo2IWjEGFiK6S0dfV2yY0Q8LnwiDm9IBpzJ1eOzT/Xhv5wWUV3KiOSJqeQwsRFQrqVSCcX3bImHuIPw5zB/VRgFLEtMw+KNf+PgzEbU4BhYiqpevSonF43theVxv+KuUuFpYhvFfHMIL357CTc6QS0QthIGFiBrkkW5+2D33T5gYHQSJBNh4PBOxH+7F1pNZfIkiETU7BhYiajA3pSPeGNEd//17f4T4uaKwtALPbziJSauO4NoNPgJNRM2HgYWILNYryAPbnxuIFx4JgVwmxd5L1/Hov3/BF/suo6raKHZ5RGSHGFiIqFHkDlI893An7Jg9EFHBnrhVWY23v/8Vjy9OwtksndjlEZGdsTiwZGVlYcKECfDy8oKTkxPCwsJw9OjRevdJTExEz549oVAo0LFjR6xevfquNp999hnatWsHpVKJqKgoHD582NLSiEgEHXxcsX56P7z7RBhUSgecydJhxGcHsPCHX3Grgo9AE1HTsCiw3Lx5EzExMXB0dMSOHTtw/vx5LFq0CB4eHnXuk56ejmHDhuHBBx/EyZMnMXv2bEybNg27du0ytfnmm28wd+5cLFiwAMePH0d4eDgGDx6M/Pz8xveMiFqMVCrB2L5tseeFQRjWIwDVRgGf/3IZgz/6BftSrotdHhHZAYlgwfD+efPm4cCBA9i3b1+Df8DLL7+M77//HmfPnjWtGzt2LIqKirBz504AQFRUFPr06YNPP/0UAGA0GqHVavHcc89h3rx59/wZer0earUaOp0OKpWqwbURUfPYcz4Pr249ixxdOQDgicg2+OdfusHTRS5yZURkTSz5/W3RFZZt27ahd+/eGDVqFHx9fREZGYnly5fXu09ycjJiY2PN1g0ePBjJyckAgIqKChw7dsysjVQqRWxsrKnNHxkMBuj1erOFiKxHbDc/7J47CJP6t4NEAmw6kYXYD/di84lMPgJNRI1iUWC5fPkylixZgk6dOmHXrl2YOXMmZs2ahTVr1tS5T25uLvz8/MzW+fn5Qa/X49atWygoKEB1dXWtbXJzc2s95sKFC6FWq02LVqu1pBtE1AJcFQ54fXgoNs3sjy7+brhRWoE535zCRD4CTUSNYFFgMRqN6NmzJ9555x1ERkZixowZmD59OpYuXdpc9dVq/vz50Ol0puXatWst+vOJqOEi23rgf88NwD8Gd4bcQYpfLl3HI//eiw93X4LuVqXY5RGRjbAosAQEBKBbt25m67p27YqMjIw69/H390deXp7Zury8PKhUKjg5OcHb2xsymazWNv7+/rUeU6FQQKVSmS1EZL0cZVLEP9gRu2b/CdHtvVBeacQnCSkY8N5P+DeDCxE1gEWBJSYmBhcvXjRbd+nSJQQFBdW5T3R0NBISEszW7d69G9HR0QAAuVyOXr16mbUxGo1ISEgwtSEi+xDs7YJ106OwZHxPdPZzQ3F5FT6+E1w+2sPgQkR1syiwzJkzBwcPHsQ777yD1NRUrFu3DsuWLUN8fLypzfz58xEXF2f6/Pe//x2XL1/GSy+9hAsXLmDx4sX49ttvMWfOHFObuXPnYvny5VizZg1+/fVXzJw5E6WlpZg8eXITdJGIrIlEIsHQsADseH4gFv8uuHy0JwUD3/sJH+9Jgb6cwYWIzFn0WDMAbN++HfPnz0dKSgqCg4Mxd+5cTJ8+3bR90qRJuHLlChITE03rEhMTMWfOHJw/fx6BgYF49dVXMWnSJLPjfvrpp/jXv/6F3NxcRERE4JNPPkFUVFSDauJjzUS2y2gUsONsLj5OuIRLeSUAAJXSAVMHtMfkAe2gUjqKXCERNRdLfn9bHFisEQMLke0zGgX8cDYHH+9JQUr+b8Fl2sD2mBzTDm4MLkR2h4GFiGxWtVHAD2dy8HFCClLvBBe1kyOmDQjGJAYXIrvCwEJENq/aKOD7Mzn45A/BZfrAYEzsz+BCZA8YWIjIblQbBWw/nY1PElKQdr0UAODu7IjpA9sjLjqIwYXIhjGwEJHdqQkuHyek4PIfgsvE/u3gqnAQuUIishQDCxHZrWqjgP+dun3F5XIBgwuRLWNgISK7V20UsO1UFj5JSEX6neDi4eyI6X9qj7hoBhciW8DAQkStRlW1EdtOZeM/P5kHlykxwYiLbge1M8e4EFkrBhYianVqgssnCSm4Unj7bdCuCgeM79cWUwcEw9dNKXKFRPRHDCxE1GpVVRvx/ZkcLP45DRfzigEAcgcpRvUKxNN/6oC2Xs4iV0hENRhYiKjVMxoF/HQhH4sTU3E8owgAIJNK8FiPAMx8oCM6+7uJWyARMbAQEdUQBAGH0m/gs59TsS+lwLQ+tqsfnnmwA3q29RCxOqLWjYGFiKgWZzJ1WLI3FTvO5qLmv3zR7b3wzIMdMKCjNyQSibgFErUyDCxERPVIzS/B53vTsPlEFqqMt/8TGNZGjfgHO+DRbv6QShlciFoCAwsRUQNkFd3C8l8uY8ORDJRXGgEAHXxc8PdBHTAysg0cZVKRKySybwwsREQWKCwxYNWBK1iTfAXF5VUAgDbuTpg+MBhj+rSFk1wmcoVE9omBhYioEYrLK/H1oQx8sS8dBSUGAICXixxTBgRjQr8gqJ04CR1RU2JgISK6D+WV1fjuWCY+35uGzJu3AABuCgdMiA7ClJhg+LgpRK6QyD4wsBARNYGqaiO2n87B4sRUXMorAQAoHKR4omcgnujZBr3aenCALtF9YGAhImpCRqOAhAv5+OznVJy8VmRa38bdCcMjNBgRoUEXf/63h8hSDCxERM1AEAQcvHwD3x27hl1nc1FaUW3a1tnPDcMjNBgeroHWk9P/EzUEAwsRUTMrr6xGwq/52HoyC4kXr6Oi2mja1jvIAyMiNPhzWAC8XDnehaguDCxERC1IV1aJnedysPVkNpIvF5pm0ZVJJRjYyRsjIjR4pJs/XBUO4hZKZGUYWIiIRJKrK8f209nYejIbZ7J0pvVKRyliu/phREQbDArxgdyBk9IRMbAQEVmBtOsl2HYyG9tOZSO9oNS0Xu3kiD+HBWBEhAZ923nySSNqtRhYiIisiCAIOJOlw9aT2fjfqWzkFxtM2/xVStNg3VCNii9gpFaFgYWIyEpVGwUculyILSezsONsrulVAMDt9xiNiGiD4eEatPN2EbFKopbBwEJEZAPKK6uRePE6tp3Kwp5f81FR9duTRj0C1XishwZ/CQ9AgNpJxCqJmg8DCxGRjdGXV+LHc3nYejILSWmFqDb+9p/mvu088Vh4AB+TJrvDwEJEZMMKSgzYcSYH/zuVg8NXbpjWy6QS9O/ghcfCNRgc6s+XMZLNY2AhIrIT2UW38P3pHPzvdDZOZ/72mLRcJsWgzj4YHq7Bw1194SznHC9kexhYiIjsUHpBKbafuv2YdEp+iWm9k6MMsd38MDxcgz+FeEPhIBOxSqKGY2AhIrJzF3L1+N+pbPzvVA4ybpSZ1rspHTAk1B/DIzSIbu8FBxknqCPrxcBCRNRKCIKA05k6bDuVje2ns5Gn/22OFy8XOf4cFoDhERr0auvBCerI6ljy+9ui6P36669DIpGYLV26dKmz/QMPPHBXe4lEgmHDhpnaTJo06a7tQ4YMsaQsIqJWSyKRIFzrjlf/0g3J8x7GNzP6YUK/tvB0kaOwtAJfHbyKUUuTEfPeT/i/78/j1LUisyeQiGyFxaO0QkNDsWfPnt8O4FD3ITZt2oSKigrT58LCQoSHh2PUqFFm7YYMGYJVq1aZPisUfGyPiMhSUqkEUe29ENXeCwseC0VSWiH+dyobu87mIkdXjuX70rF8Xzqc5TJ08XdDqEaNUI0K3TQqhPi5QenIsS9kvSwOLA4ODvD3929QW09PT7PPGzZsgLOz812BRaFQNPiYRER0b44yKQaF+GBQiA/eHtkdey9dx/9OZeOnC/koq6jG8YwiHM8oMrV3kErQ0dcV3TQqU5DpGqDio9NkNSwOLCkpKdBoNFAqlYiOjsbChQvRtm3bBu27YsUKjB07Fi4u5lNOJyYmwtfXFx4eHnjooYfw9ttvw8vLq87jGAwGGAy/3afV6/WWdoOIqNVQOsowONQfg0P9UW0UkF5QgnPZepzP1uNcth7nsnW4WVaJC7nFuJBbjE3Hs0z7aj2dEBpwO8CEtrkdZnzdFHznEbU4iwbd7tixAyUlJejcuTNycnLwxhtvICsrC2fPnoWbm1u9+x4+fBhRUVE4dOgQ+vbta1pfc9UlODgYaWlpeOWVV+Dq6ork5GTIZLVfnnz99dfxxhtv3LWeg26JiCwnCAJydOW/CzE6nMvWI6voVq3tvVzkZldiQjUqtPNy4aBesliLPSVUVFSEoKAgfPjhh5g6dWq9bZ9++mkkJyfj9OnT9ba7fPkyOnTogD179uDhhx+utU1tV1i0Wi0DCxFREyoqqzBdhTmfczvIpOaXoLYxu85yGboGqBDWRo3+HbzQr4MXVEreTqL6WRJY7mtqRHd3d4SEhCA1NbXedqWlpdiwYQPefPPNex6zffv28Pb2Rmpqap2BRaFQcGAuEVEzc3eWo39Hb/Tv6G1aV15ZjQu5xaarMOez9biQq0dZRTWOXb2JY1dvYnXSFcikEoQHqjGgkw8GdPRGZFt3OHJOGLoP9xVYSkpKkJaWhqeeeqredt999x0MBgMmTJhwz2NmZmaisLAQAQEB91MaERE1A6WjDBFad0Ro3U3rqqqNSC8oxblsPY5dvYkDqQW4XFBqGtj7SUIKXOQy9GvvhZiO3hjYyRsdfV05DoYsYtEtoRdffBGPPfYYgoKCkJ2djQULFuDkyZM4f/48fHx8EBcXhzZt2mDhwoVm+w0cOBBt2rTBhg0bzNaXlJTgjTfewJNPPgl/f3+kpaXhpZdeQnFxMc6cOdPgqyicOI6IyLpk3izDgdQC7EspQFJaIW6UVpht91MpTOElpoM3fFVKkSolMTXbLaHMzEyMGzcOhYWF8PHxwYABA3Dw4EH4+PgAADIyMiCVml/yu3jxIvbv348ff/zxruPJZDKcPn0aa9asQVFRETQaDR599FG89dZbvOVDRGTDAj2cMaZPW4zp0xZGo4DzOXocSC3A/tQCHE6/gTy9AZuOZ5meSOrs54YBnbwxoKM3otp78mWOdBdOzU9ERC2qvPL2eJd9KQXYn3od57L1+P1vIkeZBD3bemBAR28M6OSNsDZqvhPJTvFdQkREZDNulFYgKa0A+1Nu30L64+PUbkoH9O/ghQGdfBCpdUcbdye4OztyDIwdYGAhIiKbJAgCrhaWYV9qAQ6kFCAprQD68qq72jk5yqBxV0Lj7oQ27k7Q1Czq2+v81Uq+asAGMLAQEZFdqKo24kyWzjT+JTW/BAUlFffeEYC3qwJt7oSaPwYajbsTvF3lvEojMgYWIiKyW+WV1cjRlSO76Nad5c6fdbeQdWddeaXxnseRO0jNAoxGrUQ7bxd08HFFB19XuCo48Le5tdjEcURERC1N6ShDsLcLgr1dat0uCAKKyipN4eV2mDEPOHnF5aioMuJKYRmuFJbVepwAtRIdfV1NAaajjys6+LrAx5XvUhIDr7AQEVGrU1ltRO6dEJOjK0dW0e2rM5evlyA1vxQFJYY691UpHdDR19UUZmr+HOjhDBnfp2QRXmEhIiKqh6NMCq2nM7SezrVu15VVIvV6CdLyS8z+ee1GGfTlVaZZfH9P7iBFe28XdPh9kPFxRXsfFw4AbgK8wkJERNRA5ZXVuFJYitT8EtOSdr0Ul6+XwFBV+7gZiQQI9HBCRx9XdPJzQydfV4T4uaGTn2urnyCPg26JiIhaULVRQNbNW0i7/luQSb3zZ92tyjr3C/RwMoWXEF83hPi5oaOvK5zkreOKDAMLERGRFRAEAYWlFaYQk5JXjEt5JUjJL67z8WyJBNB6OCPE7/YVmRA/V3TyvR1k7O3WEgMLERGRlbtRWoFLecWmEHMprxgp+SV3vSiyhlQCtPV0NoWYED83dPJ1s+kxMgwsRERENqqgxHAnyJT89s/8YhSV1X5rSSoBgrxc0N7bBT5uCvi4KeDtWrPI4X1nnZvCweoex+ZTQkRERDaqJmz07+BtWicIAq6XGEwh5lJeze2lYujLq5BeUIr0gtJ6jyt3kMKnJsS4/j7Y3Ak1rgp431mnUlpfuGFgISIisnISiQS+bkr4uikR09E8yOQX374ik3GjDAXFFSgoMeB6sQEFJTVLBUoMVaioMprmm7kXuYMU3i5y86s1bnLMjg2Bo0hvzmZgISIislESiQR+KiX8VMp6292qqL4dZEoMKCi+HWJqAs1v4aYCBcUGFN8JN9m6cmTryk3HkMukePHRzs3dpToxsBAREdk5J7ms3onyfq+8svp3QeZOsCk2wFBlFPU2EQMLERERmSgdZQj0cEagx73DTUsS50YUERERkQUYWIiIiMjqMbAQERGR1WNgISIiIqvHwEJERERWj4GFiIiIrB4DCxEREVk9BhYiIiKyegwsREREZPUYWIiIiMjqMbAQERGR1WNgISIiIqvHwEJERERWzy7e1iwIAgBAr9eLXAkRERE1VM3v7Zrf4/Wxi8BSXFwMANBqtSJXQkRERJYqLi6GWq2ut41EaEissXJGoxHZ2dlwc3ODRCJp0mPr9XpotVpcu3YNKpWqSY9tbVpTX4HW1V/21X61pv6yr/ZHEAQUFxdDo9FAKq1/lIpdXGGRSqUIDAxs1p+hUqns+i/N77WmvgKtq7/sq/1qTf1lX+3Lva6s1OCgWyIiIrJ6DCxERERk9RhY7kGhUGDBggVQKBRil9LsWlNfgdbVX/bVfrWm/rKvrZtdDLolIiIi+8YrLERERGT1GFiIiIjI6jGwEBERkdVjYCEiIiKrx8AC4LPPPkO7du2gVCoRFRWFw4cP19v+u+++Q5cuXaBUKhEWFoYffvihhSptvIULF6JPnz5wc3ODr68vRo4ciYsXL9a7z+rVqyGRSMwWpVLZQhXfn9dff/2u2rt06VLvPrZ4XgGgXbt2d/VVIpEgPj6+1va2dl5/+eUXPPbYY9BoNJBIJNiyZYvZdkEQ8NprryEgIABOTk6IjY1FSkrKPY9r6fe+JdTX18rKSrz88ssICwuDi4sLNBoN4uLikJ2dXe8xG/NdaAn3Oq+TJk26q+4hQ4bc87jWeF6Be/e3tu+wRCLBv/71rzqPaa3ntrm0+sDyzTffYO7cuViwYAGOHz+O8PBwDB48GPn5+bW2T0pKwrhx4zB16lScOHECI0eOxMiRI3H27NkWrtwye/fuRXx8PA4ePIjdu3ejsrISjz76KEpLS+vdT6VSIScnx7RcvXq1hSq+f6GhoWa179+/v862tnpeAeDIkSNm/dy9ezcAYNSoUXXuY0vntbS0FOHh4fjss89q3f7+++/jk08+wdKlS3Ho0CG4uLhg8ODBKC8vr/OYln7vW0p9fS0rK8Px48fx6quv4vjx49i0aRMuXryI4cOH3/O4lnwXWsq9zisADBkyxKzu9evX13tMaz2vwL37+/t+5uTkYOXKlZBIJHjyySfrPa41nttmI7Ryffv2FeLj402fq6urBY1GIyxcuLDW9qNHjxaGDRtmti4qKkp4+umnm7XOppafny8AEPbu3Vtnm1WrVglqtbrlimpCCxYsEMLDwxvc3l7OqyAIwvPPPy906NBBMBqNtW635fMKQNi8ebPps9FoFPz9/YV//etfpnVFRUWCQqEQ1q9fX+dxLP3ei+GPfa3N4cOHBQDC1atX62xj6XdBDLX1deLEicKIESMsOo4tnFdBaNi5HTFihPDQQw/V28YWzm1TatVXWCoqKnDs2DHExsaa1kmlUsTGxiI5ObnWfZKTk83aA8DgwYPrbG+tdDodAMDT07PediUlJQgKCoJWq8WIESNw7ty5liivSaSkpECj0aB9+/YYP348MjIy6mxrL+e1oqICa9euxZQpU+p9Eagtn9ffS09PR25urtm5U6vViIqKqvPcNeZ7b610Oh0kEgnc3d3rbWfJd8GaJCYmwtfXF507d8bMmTNRWFhYZ1t7Oq95eXn4/vvvMXXq1Hu2tdVz2xitOrAUFBSguroafn5+Zuv9/PyQm5tb6z65ubkWtbdGRqMRs2fPRkxMDLp3715nu86dO2PlypXYunUr1q5dC6PRiP79+yMzM7MFq22cqKgorF69Gjt37sSSJUuQnp6OgQMHori4uNb29nBeAWDLli0oKirCpEmT6mxjy+f1j2rOjyXnrjHfe2tUXl6Ol19+GePGjav35XiWfhesxZAhQ/Dll18iISEB7733Hvbu3YuhQ4eiurq61vb2cl4BYM2aNXBzc8MTTzxRbztbPbeNZRdvaybLxMfH4+zZs/e81xkdHY3o6GjT5/79+6Nr1674/PPP8dZbbzV3mfdl6NChpj/36NEDUVFRCAoKwrffftug/2uxVStWrMDQoUOh0WjqbGPL55Vuq6ysxOjRoyEIApYsWVJvW1v9LowdO9b057CwMPTo0QMdOnRAYmIiHn74YREra34rV67E+PHj7zkY3lbPbWO16iss3t7ekMlkyMvLM1ufl5cHf3//Wvfx9/e3qL21efbZZ7F9+3b8/PPPCAwMtGhfR0dHREZGIjU1tZmqaz7u7u4ICQmps3ZbP68AcPXqVezZswfTpk2zaD9bPq8158eSc9eY7701qQkrV69exe7du+u9ulKbe30XrFX79u3h7e1dZ922fl5r7Nu3DxcvXrT4ewzY7rltqFYdWORyOXr16oWEhATTOqPRiISEBLP/A/296Ohos/YAsHv37jrbWwtBEPDss89i8+bN+OmnnxAcHGzxMaqrq3HmzBkEBAQ0Q4XNq6SkBGlpaXXWbqvn9fdWrVoFX19fDBs2zKL9bPm8BgcHw9/f3+zc6fV6HDp0qM5z15jvvbWoCSspKSnYs2cPvLy8LD7Gvb4L1iozMxOFhYV11m3L5/X3VqxYgV69eiE8PNzifW313DaY2KN+xbZhwwZBoVAIq1evFs6fPy/MmDFDcHd3F3JzcwVBEISnnnpKmDdvnqn9gQMHBAcHB+GDDz4Qfv31V2HBggWCo6OjcObMGbG60CAzZ84U1Gq1kJiYKOTk5JiWsrIyU5s/9vWNN94Qdu3aJaSlpQnHjh0Txo4dKyiVSuHcuXNidMEiL7zwgpCYmCikp6cLBw4cEGJjYwVvb28hPz9fEAT7Oa81qqurhbZt2wovv/zyXdts/bwWFxcLJ06cEE6cOCEAED788EPhxIkTpidj3n33XcHd3V3YunWrcPr0aWHEiBFCcHCwcOvWLdMxHnroIeE///mP6fO9vvdiqa+vFRUVwvDhw4XAwEDh5MmTZt9jg8FgOsYf+3qv74JY6utrcXGx8OKLLwrJyclCenq6sGfPHqFnz55Cp06dhPLyctMxbOW8CsK9/x4LgiDodDrB2dlZWLJkSa3HsJVz21xafWARBEH4z3/+I7Rt21aQy+VC3759hYMHD5q2DRo0SJg4caJZ+2+//VYICQkR5HK5EBoaKnz//fctXLHlANS6rFq1ytTmj32dPXu26d+Ln5+f8Oc//1k4fvx4yxffCGPGjBECAgIEuVwutGnTRhgzZoyQmppq2m4v57XGrl27BADCxYsX79pm6+f1559/rvXvbk2fjEaj8Oqrrwp+fn6CQqEQHn744bv+PQQFBQkLFiwwW1ff914s9fU1PT29zu/xzz//bDrGH/t6r++CWOrra1lZmfDoo48KPj4+gqOjoxAUFCRMnz79ruBhK+dVEO7991gQBOHzzz8XnJychKKiolqPYSvntrlIBEEQmvUSDhEREdF9atVjWIiIiMg2MLAQERGR1WNgISIiIqvHwEJERERWj4GFiIiIrB4DCxEREVk9BhYiIiKyegwsREREZPUYWIiIiMjqMbAQERGR1WNgISIiIqvHwEJERERW7/8DBxNkvXtQmSYAAAAASUVORK5CYII="
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 8: Abstract Generation"
      ],
      "metadata": {
        "id": "rwFLJ3Ly53z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_seq2(model, word_to_idx, idx_to_word, text, test_len, seq_len, device, temperature=1.0):\n",
        "    '''\n",
        "    model: Trained BiLSTM model\n",
        "    word_to_idx: Dictionary mapping words to indices\n",
        "    idx_to_word: Dictionary mapping indices to words\n",
        "    text: Initial seed text\n",
        "    test_len: Number of words to generate\n",
        "    seq_len: Length of input sequence expected by the model\n",
        "    device: The device to run the model on ('cpu' or 'cuda')\n",
        "    temperature: Controls the randomness of predictions (higher = more random)\n",
        "    '''\n",
        "\n",
        "    model.eval()\n",
        "    generated_text = text\n",
        "\n",
        "\n",
        "    tokens = text.split()\n",
        "    input_seq = [word_to_idx[token] for token in tokens if token in word_to_idx]  # Filter valid tokens\n",
        "\n",
        "\n",
        "    if not input_seq:\n",
        "        raise ValueError(\"Seed text contains no valid words from the vocabulary.\")\n",
        "\n",
        "    # Truncate or pad the sequence to `seq_len`\n",
        "    input_seq = input_seq[-seq_len:]\n",
        "    input_tensor = torch.tensor(input_seq).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(test_len):\n",
        "            # Pass the input sequence through the model\n",
        "            test_output, _ = model(input_tensor)\n",
        "\n",
        "            # Apply temperature scaling\n",
        "            logits = test_output.squeeze(0) / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            # Sample a word index from the probability distribution\n",
        "            predicted_idx = torch.multinomial(probs, 1).item()\n",
        "\n",
        "            # Get the predicted word\n",
        "            if predicted_idx not in idx_to_word:\n",
        "                # If somehow the index is invalid, skip\n",
        "                continue\n",
        "            predicted_word = idx_to_word[predicted_idx]\n",
        "\n",
        "            # Append the predicted word to the generated text\n",
        "            generated_text += ' ' + predicted_word\n",
        "\n",
        "            # Update the input sequence:\n",
        "            input_seq = input_seq[1:] + [predicted_idx]\n",
        "            input_tensor = torch.tensor(input_seq).unsqueeze(0).to(device)  # Update tensor\n",
        "\n",
        "    return generated_text\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T12:48:27.63963Z",
          "iopub.execute_input": "2024-12-05T12:48:27.639914Z",
          "iopub.status.idle": "2024-12-05T12:48:27.64831Z",
          "shell.execute_reply.started": "2024-12-05T12:48:27.639888Z",
          "shell.execute_reply": "2024-12-05T12:48:27.647459Z"
        },
        "id": "nv8Rl_bM4KRk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq2(model, word_to_idx, idx_to_word, \"impact of covid\", 100, 10, 'cuda', temperature=1.0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T12:48:27.649461Z",
          "iopub.execute_input": "2024-12-05T12:48:27.650264Z",
          "iopub.status.idle": "2024-12-05T12:48:28.170763Z",
          "shell.execute_reply.started": "2024-12-05T12:48:27.650234Z",
          "shell.execute_reply": "2024-12-05T12:48:28.169817Z"
        },
        "id": "y9-ZSt7I4KRk",
        "outputId": "8a8570c4-1910-4f39-f0ea-19a2d04f4806"
      },
      "outputs": [
        {
          "execution_count": 73,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'impact of covid patients more than could account for who th or experts in this we found significant differences with a sarscov test adverse distinct environment this observation may be to reduce the integration inhibition of severe acute respiratory tract andor time the value of the guiding members to draw conclusions prrsv plp belongs to virus surveillance for a result during recombination acts and the ai system status of complex note the continuous co monitoring which by cml patients with emphasis on transcription the epidemiology requirements of protection against on critical infection analyses enhanced loss will be reliably detected in a result were'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq2(model, word_to_idx, idx_to_word,\"outbreak of \",100,10, 'cuda', temperature=1.0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T12:49:27.10962Z",
          "iopub.execute_input": "2024-12-05T12:49:27.110258Z",
          "iopub.status.idle": "2024-12-05T12:49:27.319697Z",
          "shell.execute_reply.started": "2024-12-05T12:49:27.110222Z",
          "shell.execute_reply": "2024-12-05T12:49:27.318813Z"
        },
        "id": "6GbsnaQ24KRk",
        "outputId": "99c6112c-d74a-41e6-9998-696ff83a960a"
      },
      "outputs": [
        {
          "execution_count": 75,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'outbreak of  the new dynamics in two stage the main management of the united states taking a positive cases after even though the present low monitoring practices and we find that affect the triggered similar to their corresponding can be among humans subjects with a preliminary consumers income with covid sarscov less tightly and viruses such as well understood a large abstract recommendations knowledge in the molecular virus spreads of expenses leading to increase aortic severe acute respiratory syndrome patient presented exposures despite for people in covid positive result of the face of the average gene encoding in the accuracy of per'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq2(model,word_to_idx, idx_to_word,\"with increasing patients\",100,10, 'cuda', temperature=1.0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T12:50:15.556617Z",
          "iopub.execute_input": "2024-12-05T12:50:15.556973Z",
          "iopub.status.idle": "2024-12-05T12:50:15.757718Z",
          "shell.execute_reply.started": "2024-12-05T12:50:15.556941Z",
          "shell.execute_reply": "2024-12-05T12:50:15.756748Z"
        },
        "id": "78B1jkeD4KRk",
        "outputId": "a934809a-7871-410c-e7d4-bc3c3da36ad4"
      },
      "outputs": [
        {
          "execution_count": 77,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'with increasing patients admitted to intensive care unit resources services and not operating by rtpcr when involve level five lack of available was not observed may represent the most coronary artery disease all the outside of infections andor being predominantly clinical ejecta deposits surrounding and aa carboxyterminal end employing decoding of samples on the patient animal bodies to controls and infection and pe of symptoms which can be to help offset among healthcare environment is often to give at baseline than to the synthesis cellmediated her shins and the presence of fusion pulmonary infection by the initial chest levels genes have to competition'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generated results exhibit a sense of structure but could be improved with several enhancements.\n",
        "\n",
        "Implementing a character-level LSTM instead of a word-level approach would better capture subword patterns and handle out-of-vocabulary tokens.\n",
        "\n",
        "Additionally, the corpus, despite preprocessing (e.g., removing URLs and emails), still contains nonsensical words like \"der,\" highlighting the need for more rigorous cleaning.\n",
        "\n",
        "Using only the last hidden states of the LSTM, while computationally efficient and memory-friendly due to resource limitations, sacrifices the ability to capture the full sequence dynamics. Ideally, the entire LSTM sequence output should be utilized to better represent the context across the input.\n",
        "\n",
        "To maintain continuity during training, datasets were constructed by concatenating abstracts. However, this approach introduces the risk of generating words that, are wrongly declared contextually relevant.\n",
        "\n",
        "Finally, training could have been extended over more epochs to improve results, but GPU limitations restricted the duration. Addressing these limitations could significantly enhance the quality of the generated results."
      ],
      "metadata": {
        "id": "o0LHf2csBVe2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1awCnPIGFslD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}