{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD1VRwYz0d0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac3764a-1d9c-4469-ca96-429ff5bc931c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import torch_xla.core.xla_model as xm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = xm.xla_device()  # TPU device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjSwbv54dUfo",
        "outputId": "4f31f7ba-7617-49a6-d3a2-99aed1611429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XyxxhCydVI6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# Unzip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/pdf_json.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/extract')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Use the COVID-19 corpus\n",
        "Extract all the abstracts from the COVID-19 text files and use them as the corpus. Ensure that you create\n",
        "a vocabulary of around 10,000 words."
      ],
      "metadata": {
        "id": "5ajQYQPxOto1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTLMFSnYdp3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2c080e-bc1c-4de7-895a-46f65c0de0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.36 s, sys: 816 ms, total: 2.17 s\n",
            "Wall time: 4.42 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "'''extracting abstract from the json'''\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Function to convert JSON to text\n",
        "def json2text(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        paper_content = json.load(file)\n",
        "\n",
        "    abstract = \"\"\n",
        "    # Get the abstract\n",
        "    if 'abstract' in paper_content:\n",
        "        for abs in paper_content['abstract']:\n",
        "            abstract += abs['text']\n",
        "\n",
        "    return (f'{abstract}').lower()\n",
        "\n",
        "# Function to write converted text to file\n",
        "def write_file(filename):\n",
        "    # Convert JSON to text\n",
        "    content = json2text(filename)\n",
        "\n",
        "    # Define the output file path\n",
        "    base_name = os.path.splitext(os.path.basename(filename))[0]\n",
        "    output_dir = '/content/pdf_text'  # desired output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
        "    output_file = os.path.join(output_dir, f'{base_name}.txt')\n",
        "\n",
        "    # Writing the content to a .txt file\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "# Function for parallel processing\n",
        "def par_write(files):\n",
        "    \"\"\"\n",
        "    Read a chunk of files and let the cores of your machine\n",
        "    do the job of format conversion in parallel\n",
        "    \"\"\"\n",
        "    cpu_count = os.cpu_count()\n",
        "    p = Pool(processes=cpu_count)\n",
        "    p.map(write_file, files, chunksize=16)\n",
        "    p.close()\n",
        "\n",
        "# Directory path for JSON files\n",
        "dir_path = '/content/extract/pdf_json'\n",
        "\n",
        "# List all JSON files in the directory\n",
        "json_files = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith('.json')]\n",
        "\n",
        "# Process the files in parallel\n",
        "par_write(json_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sobUX0n_eFI_"
      },
      "outputs": [],
      "source": [
        "# Delete the folder and its contents using shell command\n",
        "!rm -rf /content/extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htnFZkjGtbJv"
      },
      "outputs": [],
      "source": [
        "def remove_urls(text):\n",
        "  '''removes all urls and email ids using regular expression'''\n",
        "\n",
        "  url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "  email_id_pattern=r\"\\S*@\\S*\\s?\"\n",
        "  clean_text=re.sub(url_pattern, '', text)\n",
        "  clean_text=re.sub(email_id_pattern, '', clean_text)\n",
        "\n",
        "  return clean_text\n",
        "\n",
        "def remove_single_letters(text):\n",
        "  '''removes all single letters except a '''\n",
        "  single_letters= r'\\b[b-zB-Z]\\b'\n",
        "  cleaned_text = re.sub(single_letters, '', text)\n",
        "  return cleaned_text\n",
        "\n",
        "def remove_brackets(text):\n",
        "    '''Removes text inside brackets '''\n",
        "    return re.sub(r'\\(.*?\\)', '', text)\n",
        "\n",
        "def remove_num_spl_char(text):\n",
        "  '''removes all numeric and special characters'''\n",
        "  corpus_num=re.sub(r'\\d+', '', text)\n",
        "  return re.sub('[^\\w\\s]', '', corpus_num)\n",
        "\n",
        "def remove_whitespace(text):\n",
        "  '''it removes all extra whitespace'''\n",
        "  return \" \".join(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mvf_48M7tgEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b4bb8d-9f78-438b-ad9c-0e1399591a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 697 ms, sys: 17.6 s, total: 18.3 s\n",
            "Wall time: 19 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import os\n",
        "import re\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def preprocess(text):\n",
        "\n",
        "    rem_urls=remove_urls(text)\n",
        "    rem_bracket_ct=remove_brackets(rem_urls)\n",
        "    rem_num_spl_char=remove_num_spl_char(rem_bracket_ct)\n",
        "    rem_singlechar=remove_single_letters(rem_num_spl_char)\n",
        "    cleaned_text=remove_whitespace(rem_singlechar)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def preprocess_file(filename):\n",
        "    \"\"\"\n",
        "    Read the content of a file, preprocess it, and save the cleaned text back to the file.\n",
        "    \"\"\"\n",
        "    with open(filename, 'r') as file:\n",
        "        text = file.read()\n",
        "          # Preprocess text\n",
        "    content = preprocess(text)\n",
        "\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "def par_write(files):\n",
        "    \"\"\"\n",
        "    Process a list of files in parallel and save the cleaned text back to the files.\n",
        "    \"\"\"\n",
        "    cpu_count = os.cpu_count()\n",
        "    p = Pool(processes=cpu_count)\n",
        "    p.map(preprocess_file, files, chunksize=50)\n",
        "    p.close()\n",
        "\n",
        "# Example usage\n",
        "dir_path = '/content/pdf_text'\n",
        "txt_files = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith('.txt')]\n",
        "par_write(txt_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnyuLY7H7GUJ",
        "outputId": "e7944698-01cf-43c7-c200-3cef4bc833be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading files: 100%|██████████| 56528/56528 [00:01<00:00, 36567.81it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "'''saving the final corpus in my drive by concat. all preprocessed .txt file'''\n",
        "\n",
        "dir = \"/content/Abstract_corpus.txt\"  # Specify the output file path\n",
        "\n",
        "# Open the output file in write mode\n",
        "with open(dir, 'a') as output_file:\n",
        "    for file_path in tqdm(txt_files, desc=\"Reading files\"):\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                content = f.read()\n",
        "                output_file.write(content)  # Write the content of each file to the output file\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while reading {file_path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqS6Nhhmu5t6"
      },
      "outputs": [],
      "source": [
        "with open('/content/Abstract_corpus.txt','r') as f:\n",
        "  corpus=f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcLLnq_u9P3O",
        "outputId": "003cb78f-2540-46ec-83eb-995809c3322e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "from collections import Counter\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def build_vocabulary(corpus, vocab_size=10000):\n",
        "    \"\"\"\n",
        "    Build a vocabulary of the most common words in the corpus.\n",
        "    \"\"\"\n",
        "    # Tokenize the corpus using NLTK\n",
        "    words = nltk.word_tokenize(corpus.lower())\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Count word frequencies and select the most common words\n",
        "    most_common_words = Counter(words).most_common(vocab_size)\n",
        "\n",
        "    # Create a vocabulary where words map to their index\n",
        "    vocabulary = {word: idx for idx, (word, _) in enumerate(most_common_words)}\n",
        "    return vocabulary\n",
        "\n",
        "vocabulary = build_vocabulary(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct One-Hot Vectors (OHVs)"
      ],
      "metadata": {
        "id": "xZuLg78UO8cs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ikuLksg12lI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot_vector(word, vocab):\n",
        "  '''creates a one hot vector for a given word'''\n",
        "    vec = np.zeros(len(vocab))\n",
        "    if word in vocab:\n",
        "        idx = vocab[word]\n",
        "        vec[idx] = 1\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture Description\n",
        "\n",
        "**SkipGram Model with Negative Sampling**\n",
        "\n",
        "The implemented architecture is a SkipGram model designed to learn word embeddings by predicting the context words of a given target word, using negative sampling to efficiently train on large vocabularies.\n",
        "\n",
        "1. **Model Components**\n",
        "\n",
        "**Input Layer**\n",
        "\n",
        "Accepts the indices of the target word, context word, and negative samples, which are each represented by unique IDs from the vocabulary.\n",
        "\n",
        "**Embedding Layers**\n",
        "\n",
        "in_embedding: Maps the target word indices to dense vector representations (Win).\n",
        "\n",
        "out_embedding: Maps context and negative word indices to dense vector representations (Wout).\n",
        "\n",
        "Each embedding layer has dimensions of (vocab_size, embedding_dim).\n",
        "\n",
        "**Output**\n",
        "\n",
        "Computes similarity scores between the target-context pair and target-negative pairs.\n",
        "\n",
        "2. **Forward Pass**\n",
        "\n",
        "**Positive Score**\n",
        "\n",
        "The model calculates a dot product between Win(target_word) and Wout(context_word) to obtain a similarity score for the true target-context pair. A loss is computed using the sigmoid activation followed by negative log-likelihood.\n",
        "\n",
        "**Negative Score**\n",
        "\n",
        "The model calculates the dot products between the target word embedding and embeddings of negative samples, Wout(negative_samples), and applies a loss function to penalize similarity with incorrect context words.\n",
        "\n",
        "3.**Loss Function**\n",
        "\n",
        "Combines positive loss (to encourage high similarity for true context words) and negative loss (to discourage similarity with negative samples), maximizing the difference between correct and incorrect predictions.\n",
        "\n",
        "4. **Training Loop**\n",
        "\n",
        "  1. **Optimizer**: Stochastic Gradient Descent (SGD) with a learning rate of 0.05.\n",
        "\n",
        "  2. **Batching**: Training data is processed in batches of size 250, stored in a PyTorch DataLoader for efficient mini-batch training.\n",
        "\n",
        "  3. **Epochs**: Model is trained for a total of 29 epochs.\n"
      ],
      "metadata": {
        "id": "2U_Dkc8PQpC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Training Pairs\n"
      ],
      "metadata": {
        "id": "hFhXogz6PGaM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63uGIHNU2SFu"
      },
      "outputs": [],
      "source": [
        "'''stores vocabulary words as index to word format'''\n",
        "inverse_vocab = {index: token for token, index in vocabulary.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOgYmSgp9AS6"
      },
      "outputs": [],
      "source": [
        "def create_vocabulary_corpus(corpus_file, vocabulary):\n",
        "  \"\"\"Creates a new corpus containing only words from the vocabulary.\"\"\"\n",
        "\n",
        "  with open(corpus_file, 'r') as f:\n",
        "    corpus = f.read()\n",
        "\n",
        "  new_corpus = \"\"\n",
        "  for word in nltk.word_tokenize(corpus.lower()):\n",
        "    if word in vocabulary:\n",
        "      new_corpus += word + \" \"\n",
        "\n",
        "  return new_corpus\n",
        "\n",
        "new_corpus = create_vocabulary_corpus('/content/Abstract_corpus.txt', vocabulary)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxzlb3SK9hb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "66f1e307-ddc6-493b-8775-492e7a06f94c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'our study aimed to investigate the factors affecting the prognosis of patients with mental disorders'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "corpus[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udw1n1v-9PJS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "08e689c3-99a5-4777-c9d6-34fac7086bed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study aimed investigate factors affecting prognosis patients mental disorders covid patients mental '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "new_corpus[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXGMu9eY_WRD"
      },
      "outputs": [],
      "source": [
        "new_corpus=new_corpus.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbJLeJV6-OUX"
      },
      "outputs": [],
      "source": [
        "context_window = 2\n",
        "'''creates the training pairs'''\n",
        "training_pairs = []\n",
        "for i, target_word in enumerate(new_corpus):\n",
        "    # Get the context words within the window\n",
        "    start = max(0, i - context_window)\n",
        "    end = min(len(new_corpus), i + context_window + 1)\n",
        "\n",
        "    context_words = [new_corpus[j] for j in range(start, end) if j != i]\n",
        "\n",
        "    # Add the (target, context) pairs\n",
        "    for context_word in context_words:\n",
        "        training_pairs.append((target_word, context_word))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVuJoZPVyKlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3351c7e4-fa44-4cb3-d6ef-7b7e36758b15",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_xla in /usr/local/lib/python3.10/dist-packages (2.5.0+libtpu)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_xla) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch_xla) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_xla) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_xla"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generated Negative Samples"
      ],
      "metadata": {
        "id": "sEOeZiaePShb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This script generates negative samples for training a SkipGram model with negative sampling.\n",
        "\n",
        "1. **Batch Processing:** Divide the training pairs into manageable batches for efficiency.\n",
        "2. **Negative Sampling:** For each target-context pair in a batch, generate `num_negative_samples` random words from the vocabulary, excluding the target and context words.\n",
        "3. **Filtering and Completion:** Ensure exactly 5 valid negative samples per pair by filtering out duplicates and sampling additional words if needed.\n",
        "4. **Output:** Store tuples of (target, context, negative_samples) in `final_training_data` for model training.\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "num_negative_samples = 5\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "vocab_array = np.array(list(vocabulary.values()))\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "temp_training_data = []\n",
        "\n",
        "\n",
        "for batch_start in tqdm(range(0, len(training_pairs), batch_size), desc=\"Generating negative samples\"):\n",
        "    batch_pairs = training_pairs[batch_start:batch_start + batch_size]\n",
        "\n",
        "\n",
        "    negative_samples_batch = np.random.choice(vocab_array, size=(len(batch_pairs), num_negative_samples), replace=True)\n",
        "\n",
        "    # Store target, context, and negative sample indices temporarily\n",
        "    for (target, context), neg_samples_indices in zip(batch_pairs, negative_samples_batch):\n",
        "        # Filter out the context word index from the negative samples\n",
        "        filtered_neg_samples = [idx for idx in neg_samples_indices if idx != vocabulary[context] and idx != vocabulary[target]]\n",
        "\n",
        "        # If there are fewer than 5 negative samples, sample more to ensure we have 5\n",
        "        if len(filtered_neg_samples) < num_negative_samples:\n",
        "            # We already filtered out the context and target word, now we need to fill up to 5 samples\n",
        "            # Sample additional negatives, excluding context and target indices\n",
        "            remaining_vocab = np.setdiff1d(vocab_array, [vocabulary[target], vocabulary[context]])\n",
        "            additional_negatives = np.random.choice(remaining_vocab, size=num_negative_samples - len(filtered_neg_samples), replace=True)\n",
        "            filtered_neg_samples.extend(additional_negatives)\n",
        "\n",
        "\n",
        "        filtered_neg_samples = filtered_neg_samples[:num_negative_samples]\n",
        "\n",
        "\n",
        "        temp_training_data.append((vocabulary[target], vocabulary[context], filtered_neg_samples))\n",
        "\n",
        "\n",
        "final_training_data = temp_training_data\n",
        "\n",
        "\n",
        "print(final_training_data[:5])\n",
        "\n",
        "# Check if all entries now have 5 negative samples\n",
        "for idx, (target_idx, context_idx, negative_indices) in enumerate(final_training_data):\n",
        "    if len(negative_indices) < 5:\n",
        "        print(f\"Warning: Entry {idx} still has fewer than 5 negative samples.\")\n"
      ],
      "metadata": {
        "id": "1PxW4A2nS-Tl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc29b76-8e53-4217-8255-fd1f44d0f728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating negative samples: 100%|██████████| 17763/17763 [01:37<00:00, 181.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(4, 511, [3606, 1565, 1403, 2740, 818]), (4, 424, [9714, 439, 1633, 532, 1475]), (511, 4, [8389, 6783, 9066, 1569, 5315]), (511, 424, [8873, 4291, 3477, 4554, 6266]), (511, 59, [5553, 3174, 7108, 1422, 8136])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Data\n",
        "The provided code creates a PyTorch DataLoader to efficiently batch and shuffle training data for the SkipGram model."
      ],
      "metadata": {
        "id": "9JaiQZnCPXc0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6JpGiz70bGS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "targets, contexts, negatives = zip(*final_training_data)\n",
        "\n",
        "targets_tensor = torch.tensor(targets, dtype=torch.long)\n",
        "contexts_tensor = torch.tensor(contexts, dtype=torch.long)\n",
        "negatives_tensor = torch.tensor(negatives, dtype=torch.long)\n",
        "\n",
        "# Create TensorDataset and DataLoader for batching\n",
        "dataset = TensorDataset(targets_tensor, contexts_tensor, negatives_tensor)\n",
        "batch_size = 250  # Adjust batch size as needed\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SkipGramModel using Negative Sampling"
      ],
      "metadata": {
        "id": "xLzJoglFPwu6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gZA2PZk1N5K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SkipGramModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(SkipGramModel, self).__init__()\n",
        "        self.in_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.out_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, target_word, context_word, negative_samples):\n",
        "        target_embedding = self.in_embedding(target_word)  # (batch_size, embedding_dim)\n",
        "        context_embedding = self.out_embedding(context_word)  # (batch_size, embedding_dim)\n",
        "        neg_samples_embedding = self.out_embedding(negative_samples)  # (batch_size, num_neg_samples, embedding_dim)\n",
        "\n",
        "        # Positive score\n",
        "        pos_score = torch.mul(target_embedding, context_embedding).sum(dim=1)\n",
        "        pos_loss = torch.log(torch.sigmoid(pos_score)).mean()\n",
        "\n",
        "        # Negative score\n",
        "        neg_score = torch.bmm(neg_samples_embedding, target_embedding.unsqueeze(2)).squeeze()\n",
        "        neg_loss = torch.log(torch.sigmoid(-neg_score)).mean()\n",
        "\n",
        "        return - (pos_loss + neg_loss)  # Negative log likelihood loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "B-qjiwSoTHdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "vocab_size = len(vocabulary)  # Set to the size of your vocabulary\n",
        "embedding_dim = 100  # Embedding size\n",
        "learning_rate = 0.05\n",
        "num_epochs = 18\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "model = SkipGramModel(vocab_size, embedding_dim)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epoch_loss=[]\n",
        "# Training loop with tqdm progress bar\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    # Use tqdm for batch progress tracking\n",
        "    with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
        "        for target_word, context_word, negative_samples in pbar:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            loss = model(target_word, context_word, negative_samples)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Update progress bar with loss information\n",
        "            pbar.set_postfix(loss=total_loss / (pbar.n + 1))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}\")\n",
        "    epoch_loss.append(total_loss / len(dataloader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czJrqeTiTSsp",
        "outputId": "0a4d4833-1152-4d45-f3cb-db4750e64437",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/18: 100%|██████████| 71049/71049 [07:37<00:00, 155.32it/s, loss=6.91]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 6.910019588721465\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/18: 100%|██████████| 71049/71049 [07:49<00:00, 151.44it/s, loss=5.47]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 5.472267563736436\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/18: 100%|██████████| 71049/71049 [07:38<00:00, 154.87it/s, loss=4.67]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 4.670370435947607\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/18: 100%|██████████| 71049/71049 [07:46<00:00, 152.31it/s, loss=4.13]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 4.129143464872155\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/18: 100%|██████████| 71049/71049 [07:39<00:00, 154.60it/s, loss=3.73]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 3.7284655440481016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/18: 100%|██████████| 71049/71049 [07:39<00:00, 154.50it/s, loss=3.41]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 3.4142392871364717\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/18: 100%|██████████| 71049/71049 [07:47<00:00, 151.88it/s, loss=3.16]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 3.158063875529719\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/18: 100%|██████████| 71049/71049 [07:36<00:00, 155.58it/s, loss=2.94]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 2.943664481049965\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/18: 100%|██████████| 71049/71049 [07:40<00:00, 154.14it/s, loss=2.76]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 2.7609917793229095\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/18: 100%|██████████| 71049/71049 [07:46<00:00, 152.27it/s, loss=2.6]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 2.603525369046087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/18: 100%|██████████| 71049/71049 [07:46<00:00, 152.30it/s, loss=2.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 2.466770117090821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/18: 100%|██████████| 71049/71049 [07:38<00:00, 154.83it/s, loss=2.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 2.347415416475154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/18: 100%|██████████| 71049/71049 [07:47<00:00, 152.09it/s, loss=2.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 2.2428636023707287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/18: 100%|██████████| 71049/71049 [07:40<00:00, 154.18it/s, loss=2.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 2.1509792081918686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/18: 100%|██████████| 71049/71049 [07:53<00:00, 150.19it/s, loss=2.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 2.069981329568486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/18: 100%|██████████| 71049/71049 [07:38<00:00, 154.79it/s, loss=2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 1.9983012643067997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/18: 100%|██████████| 71049/71049 [07:46<00:00, 152.28it/s, loss=1.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 1.934559297945201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/18: 100%|██████████| 71049/71049 [07:36<00:00, 155.76it/s, loss=1.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 1.8775941802590626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Due to TPU usage limitations,have saved and retrained the model'''\n",
        "# Hyperparameters\n",
        "vocab_size = len(vocabulary)  # Set to the size of your vocabulary\n",
        "embedding_dim = 100  # Embedding size\n",
        "learning_rate = 0.05\n",
        "num_epochs = 15\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epoch_loss=[]\n",
        "# Training loop with tqdm progress bar\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    # Use tqdm for batch progress tracking\n",
        "    with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
        "        for target_word, context_word, negative_samples in pbar:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            loss = model(target_word, context_word, negative_samples)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Update progress bar with loss information\n",
        "            pbar.set_postfix(loss=total_loss / (pbar.n + 1))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}\")\n",
        "    epoch_loss.append(total_loss / len(dataloader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "cLqOp0qyzOrX",
        "outputId": "050eb6fa-0814-4e4f-9acb-537733029823",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15: 100%|██████████| 71049/71049 [07:22<00:00, 160.55it/s, loss=1.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.7151104715228203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|██████████| 71049/71049 [07:43<00:00, 153.44it/s, loss=1.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 1.6785950873305449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 100%|██████████| 71049/71049 [07:28<00:00, 158.45it/s, loss=1.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.6449908090628693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|██████████| 71049/71049 [07:42<00:00, 153.60it/s, loss=1.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 1.613928753599248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 100%|██████████| 71049/71049 [07:43<00:00, 153.26it/s, loss=1.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 1.5851042181516435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 100%|██████████| 71049/71049 [07:30<00:00, 157.70it/s, loss=1.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 1.5582621072145328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15: 100%|██████████| 71049/71049 [07:49<00:00, 151.17it/s, loss=1.53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 1.5331711142327804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15: 100%|██████████| 71049/71049 [07:28<00:00, 158.42it/s, loss=1.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 1.509668482635343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15: 100%|██████████| 71049/71049 [07:55<00:00, 149.46it/s, loss=1.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 1.487576592225079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15: 100%|██████████| 71049/71049 [07:34<00:00, 156.16it/s, loss=1.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.4667547595588362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 100%|█████████▉| 70928/71049 [07:39<00:00, 154.52it/s, loss=1.45]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-8c7a8e505c63>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Backward pass and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0d2656916ce1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, target_word, context_word, negative_samples)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Negative score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mneg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_samples_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mneg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mneg_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneg_loss\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Negative log likelihood loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss vs Epoch"
      ],
      "metadata": {
        "id": "fvrjU92CQONT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(29 ), epoch_loss, marker='o', color='b', label='Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Epoch vs Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Nn0h9hOzFROG",
        "outputId": "4eff165d-81c2-4c08-8e69-8c790978eb7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving & Loading the model"
      ],
      "metadata": {
        "id": "DfjjKw6XQWhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/skipgram_model_weights_assignment.pth')\n"
      ],
      "metadata": {
        "id": "AXisdv0hCeN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the model\n",
        "\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "# Load the training pairs\n",
        "training_pairs_save_path = '/content/drive/MyDrive/training_pairs.pkl'\n",
        "with open(training_pairs_save_path, 'rb') as f:\n",
        "    final_training_data = pickle.load(f)\n",
        "\n",
        "print(f\"Training pairs loaded: {len(final_training_data)} pairs.\")\n",
        "\n",
        "# Load the vocabulary\n",
        "vocab_save_path = '/content/drive/MyDrive/vocabulary.pkl'\n",
        "with open(vocab_save_path, 'rb') as f:\n",
        "    vocabulary = pickle.load(f)\n",
        "\n",
        "print(f\"Vocabulary loaded: {len(vocabulary)} words.\")\n",
        "\n",
        "\n",
        "\n",
        "vocab_size = len(vocabulary)\n",
        "embedding_dim = 100\n",
        "\n",
        "model = SkipGramModel(vocab_size, embedding_dim)\n",
        "\n",
        "# Load the saved model weights\n",
        "model_save_path = '/content/drive/MyDrive/skipgram_model_weights_assignment.pth'\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()\n",
        "print(\"Model loaded successfully.\")\n"
      ],
      "metadata": {
        "id": "Ps7zbBpSGTPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Analogies"
      ],
      "metadata": {
        "id": "8aYxL8jtQbHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def test_analogy_cosine(model, word_a, word_b, word_c, word_to_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Perform analogy testing using cosine similarity.\n",
        "    Answers the question: 'word_a is to word_b as word_c is to ?'\n",
        "\n",
        "    Returns the top_n closest words to the analogy vector.\n",
        "    \"\"\"\n",
        "    # Get embeddings for each word\n",
        "    try:\n",
        "        vec_a = model.in_embedding.weight[word_to_id[word_a]].detach().cpu().numpy().reshape(1, -1)\n",
        "        vec_b = model.in_embedding.weight[word_to_id[word_b]].detach().cpu().numpy().reshape(1, -1)\n",
        "        vec_c = model.in_embedding.weight[word_to_id[word_c]].detach().cpu().numpy().reshape(1, -1)\n",
        "    except KeyError as e:\n",
        "        print(f\"Word not found in vocabulary: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Calculate the analogy vector: word_b - word_a + word_c\n",
        "    analogy_vector = vec_b - vec_a + vec_c\n",
        "\n",
        "    # List to store the similarity scores for words\n",
        "    similarities = []\n",
        "\n",
        "    # Iterate over vocabulary to find the most similar words, excluding original words\n",
        "    for word, idx in word_to_id.items():\n",
        "        if word in [word_a, word_b, word_c]:  # Exclude original words\n",
        "            continue\n",
        "\n",
        "        vec_d = model.in_embedding.weight[idx].detach().cpu().numpy().reshape(1, -1)\n",
        "\n",
        "        # Calculate cosine similarity between analogy vector and each word vector\n",
        "        similarity = cosine_similarity(analogy_vector, vec_d)[0][0]\n",
        "        similarities.append((word, similarity))\n",
        "\n",
        "    # Sort words by similarity and return top_n closest words\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_n]\n",
        "\n",
        "\n",
        "word_a = 'social'\n",
        "word_b = 'distancing'\n",
        "word_c = 'quarantine'\n",
        "\n",
        "top_n = 5\n",
        "results = test_analogy_cosine(model, word_a, word_b, word_c, vocabulary, top_n)\n",
        "\n",
        "if results:\n",
        "    for word, similarity in results:\n",
        "        print(f\"'{word}' (similarity: {similarity:.4f})\")\n",
        "else:\n",
        "    print(\"Analogy test failed. Ensure all words are in vocabulary.\")\n"
      ],
      "metadata": {
        "id": "jWlzhoPyloHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a9d6c4c-6352-4fd0-dc0e-ddb404d91902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'diagnosis' (similarity: 0.7577)\n",
            "'suggests' (similarity: 0.7533)\n",
            "'worldwide' (similarity: 0.7525)\n",
            "'prevention' (similarity: 0.7497)\n",
            "'conclusions' (similarity: 0.7452)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TASK 2\n",
        "\n",
        "1.   **Find similar words for a word of your choice using Win**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4TX7NTtvIDMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def find_similar_words_win(model, word, word_to_id, top_n=5):\n",
        "    '''Finds the top-N words most similar to a given word using the `in_embedding matrix.'''\n",
        "\n",
        "    try:\n",
        "        vec = model.in_embedding.weight[word_to_id[word]].detach().cpu().numpy().reshape(1, -1)\n",
        "    except KeyError as e:\n",
        "        print(f\"Word not found in vocabulary: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "\n",
        "    for other_word, idx in word_to_id.items():\n",
        "        if other_word == word:  # Exclude the original word\n",
        "            continue\n",
        "\n",
        "        vec_other = model.in_embedding.weight[idx].detach().cpu().numpy().reshape(1, -1)\n",
        "\n",
        "\n",
        "        similarity = cosine_similarity(vec, vec_other)[0][0]\n",
        "        similarities.append((other_word, similarity))\n",
        "\n",
        "\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_n]\n",
        "\n",
        "\n",
        "word = 'social'\n",
        "results_win = find_similar_words_win(model, word, vocabulary, top_n=5)\n",
        "if results_win:\n",
        "    for word, similarity in results_win:\n",
        "        print(f\"'{word}' (similarity: {similarity:.4f})\")\n",
        "else:\n",
        "    print(\"Word not found in vocabulary.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjZw4ia0ViRw",
        "outputId": "ca44b0d4-8951-4272-d311-5d4d11ea5b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'impact' (similarity: 0.9124)\n",
            "'global' (similarity: 0.9101)\n",
            "'community' (similarity: 0.9074)\n",
            "'distancing' (similarity: 0.9072)\n",
            "'measures' (similarity: 0.9065)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.   **Find the similar words for the same word chosen in (1) using Wout**\n",
        "\n"
      ],
      "metadata": {
        "id": "IyBPJ5xLHzfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_words_wout(model, word, word_to_id, top_n=5):\n",
        "  '''Finds the top-N words most similar to a given word using the out_embedding matrix.'''\n",
        "\n",
        "    try:\n",
        "        vec = model.out_embedding.weight[word_to_id[word]].detach().cpu().numpy().reshape(1, -1)\n",
        "    except KeyError as e:\n",
        "        print(f\"Word not found in vocabulary: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "\n",
        "    for other_word, idx in word_to_id.items():\n",
        "        if other_word == word:\n",
        "            continue\n",
        "\n",
        "        vec_other = model.out_embedding.weight[idx].detach().cpu().numpy().reshape(1, -1)\n",
        "\n",
        "\n",
        "        similarity = cosine_similarity(vec, vec_other)[0][0]\n",
        "        similarities.append((other_word, similarity))\n",
        "\n",
        "\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_n]\n",
        "\n",
        "\n",
        "word = 'social'\n",
        "results_wout = find_similar_words_wout(model, word, vocabulary, top_n=5)\n",
        "if results_wout:\n",
        "    for word, similarity in results_wout:\n",
        "        print(f\"'{word}' (similarity: {similarity:.4f})\")\n",
        "else:\n",
        "    print(\"Word not found in vocabulary.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQmZG2N7F73C",
        "outputId": "6415ffae-e755-4aec-c7e3-21350d1752a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'health' (similarity: 0.9105)\n",
            "'pandemic' (similarity: 0.8656)\n",
            "'new' (similarity: 0.8637)\n",
            "'study' (similarity: 0.8593)\n",
            "'data' (similarity: 0.8587)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.   **Find the similar words for the same word chosen in (1) after combining Win and Wout - either concatenate them to have a longer vector or average them out**\n",
        "\n"
      ],
      "metadata": {
        "id": "ijaiHlcAH36f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_words_combined_avg(model, word, word_to_id, top_n=5):\n",
        "  '''Finds the top-N words most similar to a given word using the averaged embeddings from `Win` and `Wout`.'''\n",
        "\n",
        "    try:\n",
        "        vec_win = model.in_embedding.weight[word_to_id[word]].detach().cpu().numpy().reshape(1, -1)\n",
        "        vec_wout = model.out_embedding.weight[word_to_id[word]].detach().cpu().numpy().reshape(1, -1)\n",
        "    except KeyError as e:\n",
        "        print(f\"Word not found in vocabulary: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    combined_vec = (vec_win + vec_wout) / 2\n",
        "\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "\n",
        "    for other_word, idx in word_to_id.items():\n",
        "        if other_word == word:  # Exclude the original word\n",
        "            continue\n",
        "\n",
        "        vec_win_other = model.in_embedding.weight[idx].detach().cpu().numpy().reshape(1, -1)\n",
        "        vec_wout_other = model.out_embedding.weight[idx].detach().cpu().numpy().reshape(1, -1)\n",
        "\n",
        "\n",
        "        combined_vec_other = (vec_win_other + vec_wout_other) / 2\n",
        "\n",
        "\n",
        "        similarity = cosine_similarity(combined_vec, combined_vec_other)[0][0]\n",
        "        similarities.append((other_word, similarity))\n",
        "\n",
        "\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_n]\n",
        "\n",
        "\n",
        "word='social'\n",
        "results_combined_avg = find_similar_words_combined_avg(model, word, vocabulary, top_n=5)\n",
        "if results_combined_avg:\n",
        "    for word, similarity in results_combined_avg:\n",
        "        print(f\"'{word}' (similarity: {similarity:.4f})\")\n",
        "else:\n",
        "    print(\"Word not found in vocabulary.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjpuxySpG3wL",
        "outputId": "58ac7bb4-0c89-4071-af9f-f0a4c2d54a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'health' (similarity: 0.9436)\n",
            "'pandemic' (similarity: 0.9145)\n",
            "'data' (similarity: 0.8954)\n",
            "'covid' (similarity: 0.8953)\n",
            "'current' (similarity: 0.8891)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Comparing results\n",
        "\n",
        "  1. **W_in** is optimized to encode the semantics of the target word itself, trying to predict the context words for the word(social here).Words like impact, community, and global suggest that it attempts to capture semantic relationships and broader contextual meanings associated with the target word (social in this case). These words align well with the conceptual understanding of \"social\" as it relates to societal and community aspects.\n",
        "\n",
        "\n",
        "  2. **W_out** is optimized to represent the context words in whose surrounding the target word appears. Words like health, pandemic, new, study, and data imply that Wout captures the typical surrounding contexts in which \"social\" is used in the training corpus. For example, \"social health\" or \"social data\" might frequently occur in corpus, connecting social to those terms in specific contexts.\n",
        "\n",
        "  3. With **averaging W_in and W_out**,we combine semantic meaning and contextual usage. Words health, pandemic, and data, which reflect both thematic relevance (semantic meaning) and contextual association in the COVID-19 corpus. This results in embeddings that are neither too general nor too specific but strike a meaningful balance.\n",
        "\n"
      ],
      "metadata": {
        "id": "YaDwGOJ-1PAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.Time Complexity\n",
        "\n",
        "  1. **Generating training pairs**\n",
        "        * The outer loop runs over each word in the corpus: O(T) where T is the number of words in new_corpus. For each word i, it considers a context window of size C i.e., O(C). The total time complexity for this step is: O(T.C)\n",
        "\n",
        "  2. **Negative sampling**\n",
        "        * The number of training pairs to process is O(T.C), and we sample k negative samples for each pair. Sampling from the vocabulary requires\n",
        "        O(k) time per pair. Hence, O(T.C.k) where k is the number of negative samples for each pair\n",
        "\n",
        "  3. **Forward Pass**\n",
        "        * There are 1 target, 1 context word, and k negative samples, so embedding lookup for each word is O(d) and positive score is calculated using a dot product, which takes O(d) for each pair.\n",
        "        * Embedding lookups for all T.C word-context pairs with k negative samples :O(T⋅C⋅k⋅d), k is number of negative samples and d is the embedding dimension\n",
        "        * Score calculations for all pairs: O(T⋅C⋅k⋅d)\n",
        "        * Loss calculations for all pairs: O(T⋅C⋅k)\n",
        "        * So, the total time complexity (with T training samples and C context words) is: O(T⋅C⋅k⋅d)\n",
        "\n",
        "  4. **Full Training Loop**\n",
        "        * If N is the number of epochs trainig is done for, then\n",
        "        Total time complexity is O(N.T⋅C⋅k⋅d)\n",
        "\n",
        "  which aligns with the complexity mentioned in slides. Hence, the mentioned complexities in the slide is correct.\n",
        "\n"
      ],
      "metadata": {
        "id": "0qvm8JVh-GSS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "shuWiy4519vh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}